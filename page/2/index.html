<!DOCTYPE html>



  


<html class="theme-next muse use-motion" lang="">
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hexo, NexT">










<meta name="description" content="Stay Hungry, Stay Foolish">
<meta name="keywords" content="test">
<meta property="og:type" content="website">
<meta property="og:title" content="Leesine&#39;s Blog">
<meta property="og:url" content="http://yoursite.com/page/2/index.html">
<meta property="og:site_name" content="Leesine&#39;s Blog">
<meta property="og:description" content="Stay Hungry, Stay Foolish">
<meta property="og:locale" content="default">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Leesine&#39;s Blog">
<meta name="twitter:description" content="Stay Hungry, Stay Foolish">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Muse',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://yoursite.com/page/2/">





  <title>Leesine's Blog</title>
  








</head>

<body itemscope="" itemtype="http://schema.org/WebPage" lang="default">

  
  
    
  

  <div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope="" itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Leesine's Blog</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">Stay Hungry, Stay Foolish</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            Archives
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/01/24/leveldb-compaction/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Leeshine">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Leesine's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/01/24/leveldb-compaction/" itemprop="url">LevelDB Compaction</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-01-24T21:24:17+08:00">
                2019-01-24
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="作用"><a href="#作用" class="headerlink" title="作用"></a>作用</h2><p>LevelDB中将随机写在内存中缓存并进行排序(memtable)，从而将随机写转化成顺序写来提高数据的写入速度，在磁盘上它是以sstable的格式来持久化存储数据的。磁盘上的sstable文件是分层存储的，层级越高，容量就越大，存储的文件就越旧。随着数据的持续写入，memtable达到阈值之后会flush到level 0的sstable中，这个过程被称之为minor compaction，由于这一层级的文件是有memtable直接刷写下来的，所以sstable之间的key可能会存在重叠。</p>
<p>在查找一个key时，系统会先去memtable中查找，若未找到，则会按层级去sstable中查找。由于level 0中的sstable中的key是可能重叠的，所以在查找level0时可能要遍历多个sstable文件，这样会导致查询效率较低。所以当level 0中的文件数较多时，会出发major compaction，将该层的文件同下层合并。</p>
<p>level 0以上的文件是通过compaction来生成的，所以同一层的文件之间的key是不存在重叠的，但是该层的文件量也不能太大，否则会降低key的查找效率。同时，文件量太大也会造成major compaction的时候IO负载过高，影响系统的正常读写。所以LevelDB中会分多层来存储sstable文件，层级越高，容量越大，所存储的文件也越久。</p>
<p>综上，Compaction的机制如下：</p>
<ul>
<li>当memtable达到阈值时，会触发minor compaction，将memtable中的数据flush成sstable文件，防止占用过多内存</li>
<li>当level 0中的文件数过多时，会触发major compaction，将该层的部分文件与上层合并，提高查询效率</li>
<li>当level 0以上某层文件总量过大时，会触发major compaction，提高查询效率，同时避免之后参与compaction的数据量过大</li>
</ul>
<h2 id="流程"><a href="#流程" class="headerlink" title="流程"></a>流程</h2><h3 id="Compaction"><a href="#Compaction" class="headerlink" title="Compaction"></a>Compaction</h3><p>Compaction最终是通过调用<code>BackgroundCompaction</code>来执行的，执行流程如下：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line">BackgroundCompaction() &#123;</span><br><span class="line">	<span class="keyword">if</span>(imm_ != <span class="literal">NULL</span>) &#123;</span><br><span class="line">      	<span class="comment">//minor compaction</span></span><br><span class="line">		CompactMemtable() ;</span><br><span class="line">		<span class="keyword">return</span> ;</span><br><span class="line">	&#125;</span><br><span class="line">	</span><br><span class="line">    <span class="comment">//major compaction</span></span><br><span class="line">	<span class="keyword">if</span>(is_manual) &#123;</span><br><span class="line">		ManualCompaction* m = manual_compaction_;</span><br><span class="line">    	c = versions_-&gt;CompactRange(m-&gt;level, m-&gt;begin, m-&gt;end);</span><br><span class="line">	&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">		 c = versions_-&gt;PickCompaction();</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="keyword">if</span> (c == <span class="literal">NULL</span>) &#123;</span><br><span class="line">    	<span class="comment">// Nothing to do</span></span><br><span class="line">  	&#125; <span class="keyword">else</span> <span class="keyword">if</span> (!is_manual &amp;&amp; c-&gt;IsTrivialMove()) &#123;</span><br><span class="line">      	<span class="comment">//平移文件至下一层</span></span><br><span class="line">	    c-&gt;edit()-&gt;DeleteFile(c-&gt;level(), f-&gt;number);</span><br><span class="line">    	c-&gt;edit()-&gt;AddFile(c-&gt;level() + <span class="number">1</span>, f-&gt;number, f-&gt;file_size, f-&gt;smallest, f-&gt;largest);</span><br><span class="line">    	status = versions_-&gt;LogAndApply(c-&gt;edit(), &amp;mutex_);</span><br><span class="line">  	&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">  		DoCompactionWork(compact);</span><br><span class="line">  	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>整体的流程图如下：</p>
<p><img src="/images/level/pic1.png" alt=""></p>
<h3 id="Minor-Compaction"><a href="#Minor-Compaction" class="headerlink" title="Minor Compaction"></a>Minor Compaction</h3><p>其中，<code>CompactMemtable</code>用以将memtable中的文件flush成sstable文件，它的流程如下：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">CompactMemtable() &#123;</span><br><span class="line">	VersionEdit edit;</span><br><span class="line">  	Version* base = versions_-&gt;current();</span><br><span class="line">  	<span class="comment">//将数据刷写至sstable中</span></span><br><span class="line">  	Status s = WriteLevel0Table(imm_, &amp;edit, base);</span><br><span class="line">  	versions_-&gt;LogAndApply(&amp;edit, &amp;mutex_);</span><br><span class="line">  	DeleteObsoleteFiles();</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>以上流程中，Version是系统用来管理系统中sstable文件的，每次进行compact后，都会新生成一个Version用来管理磁盘上sstable文件的状态，VersionEdit则代表此次compact中文件的变化情况，关于Version机制会在下节讨论。</p>
<p>在<code>CompactMemtable</code>中会调用<code>WriteLevel0Table</code>将<code>memtable</code>刷写至<code>sstable</code>中，机制如下：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">WriteLevel0Table(MemTable* mem, VersionEdit* edit, Version* base) &#123;</span><br><span class="line">	FileMetaData meta; </span><br><span class="line">	BuildTable(dbname_, env_, options_, table_cache_, iter, &amp;meta);</span><br><span class="line"></span><br><span class="line">	<span class="keyword">if</span>(meta.file_size &gt; <span class="number">0</span>) &#123;</span><br><span class="line">		<span class="keyword">if</span> (base != <span class="literal">NULL</span>) &#123;</span><br><span class="line">			<span class="comment">//为minor compact形成的sstfile选择合适的层级，memtable不一定是compact至level0中</span></span><br><span class="line">			<span class="comment">//如果level0中存在与此次compact key重叠的文件，则直接flush至level0</span></span><br><span class="line">			<span class="comment">//否则可以沉降至没有重叠区间的一个level，且沉降至该level后不会造成之后的大量compaction（与level+1层的重叠不能过多）</span></span><br><span class="line">      		level = base-&gt;PickLevelForMemTableOutput(min_user_key, max_user_key);</span><br><span class="line">    	&#125;</span><br><span class="line">    	<span class="comment">//添加一个sstfile</span></span><br><span class="line">    	edit-&gt;AddFile(level, meta.number, meta.file_size,</span><br><span class="line">                meta.smallest, meta.largest);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>其中，需要注意的是，memtable不总是直接flush值level 0中的，如果level 0中没有文件与memtable的数据重合，则可以直接刷写至更高的层级，这样可以减少compaction的次数。但同时，如果某一层（level层）没有文件与memtable中的数据重合，但是下一层（level+1）中与memtable中重合的文件尺寸较大，也不能直接放入level中，否则的话会导致之后该文件compaction的时候设计到的数据量太大，影响系统的正常读写。</p>
<h3 id="Major-Compaction"><a href="#Major-Compaction" class="headerlink" title="Major Compaction"></a>Major Compaction</h3><p>Major Compaction的第一步是选择生成compaction的信息，根据compaction是否是手动触发的，具体机制又有不同，如下：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//根据手动compact时输入的level及key的范围生成compact信息</span></span><br><span class="line"><span class="comment">//compact信息中最重要的信息就是inputs，即参与compaction的sstfile</span></span><br><span class="line"><span class="comment">//其中inputs[0]中存储的是level层的文件</span></span><br><span class="line"><span class="comment">//inputs是与inputs[0]中的key存在交集的level+1层的文件</span></span><br><span class="line">CompactRange(level, begin, end) &#123;</span><br><span class="line">	<span class="comment">//获取第一层待compact的文件</span></span><br><span class="line">	current_-&gt;GetOverlappingInputs(level, begin, end, &amp;inputs);</span><br><span class="line">  	<span class="keyword">if</span> (inputs.empty()) &#123;</span><br><span class="line">   		<span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line">  	&#125;</span><br><span class="line"></span><br><span class="line">  	Compaction* c = <span class="keyword">new</span> Compaction(options_, level);</span><br><span class="line">  	c-&gt;inputs_[<span class="number">0</span>] = inputs;</span><br><span class="line">  	<span class="comment">//获取下一层被compact的文件</span></span><br><span class="line">  	SetupOtherInputs(c);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">PickCompaction() &#123;</span><br><span class="line">	<span class="comment">//根据某层的总容量或者查找次数来触发compaction，其中容量触发的优先级更高</span></span><br><span class="line">	<span class="keyword">const</span> <span class="keyword">bool</span> size_compaction = (current_-&gt;compaction_score_ &gt;= <span class="number">1</span>);</span><br><span class="line">  	<span class="keyword">const</span> <span class="keyword">bool</span> seek_compaction = (current_-&gt;file_to_compact_ != <span class="literal">NULL</span>);</span><br><span class="line"></span><br><span class="line">  	<span class="keyword">if</span> (size_compaction) &#123;</span><br><span class="line">  		level = current_-&gt;compaction_level_;</span><br><span class="line">    	c = <span class="keyword">new</span> Compaction(options_, level);</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Pick the first file that comes after compact_pointer_[level]</span></span><br><span class="line">    <span class="comment">// compact_pointer_中记录的是每层上次compaction中最大的key，选择上次最大的key后的一个文件</span></span><br><span class="line">    <span class="keyword">for</span> (<span class="keyword">size_t</span> i = <span class="number">0</span>; i &lt; current_-&gt;files_[level].size(); i++) &#123;</span><br><span class="line">      FileMetaData* f = current_-&gt;files_[level][i];</span><br><span class="line">      <span class="keyword">if</span> (compact_pointer_[level].empty() ||</span><br><span class="line">          icmp_.Compare(f-&gt;largest.Encode(), compact_pointer_[level]) &gt; <span class="number">0</span>) &#123;</span><br><span class="line">        c-&gt;inputs_[<span class="number">0</span>].push_back(f);</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">if</span> (c-&gt;inputs_[<span class="number">0</span>].empty()) &#123;</span><br><span class="line">      <span class="comment">// Wrap-around to the beginning of the key space</span></span><br><span class="line">      <span class="comment">//未选到文件的话，则选择第一个文件来进行compact</span></span><br><span class="line">      c-&gt;inputs_[<span class="number">0</span>].push_back(current_-&gt;files_[level][<span class="number">0</span>]);</span><br><span class="line">      &#125;</span><br><span class="line">  	&#125; <span class="keyword">else</span> <span class="keyword">if</span> (seek_compaction) &#123;</span><br><span class="line">  		c-&gt;inputs_[<span class="number">0</span>].push_back(current_-&gt;file_to_compact_)a</span><br><span class="line">  	&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">  		<span class="keyword">return</span> <span class="literal">NULL</span>;</span><br><span class="line">  	&#125;</span><br><span class="line">  	<span class="comment">//根据inputs[0]来生成inputs[1]</span></span><br><span class="line">  	SetupOtherInputs(c);</span><br><span class="line">  	<span class="keyword">return</span> c;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>生成compaction信息后，便可开始compaction流程，如果level+1没有文件与待compaction的文件存在重叠，则可以考虑将文件直接下移，但是下移后也不能造成之后的compaction数据量过大，LevelDB这里是通过grandparent层级(level+2)的重叠数据量来判断的:</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">IsTrivialMove() &#123;</span><br><span class="line">	<span class="comment">//如果level+2层存在与compact_range重合的数据较大，则不允许直接移动文件，否则之后会造成大量的compaction</span></span><br><span class="line">	 <span class="keyword">return</span> (num_input_files(<span class="number">0</span>) == <span class="number">1</span> &amp;&amp; num_input_files(<span class="number">1</span>) == <span class="number">0</span> &amp;&amp;</span><br><span class="line">          TotalFileSize(grandparents_) &lt;=</span><br><span class="line">            MaxGrandParentOverlapBytes(vset-&gt;options_));</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>如果不是直接平移，则调用<code>DoCompactionWork</code>来修改sstable，机制如下：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//根据输入在高层生成新的sstfile</span></span><br><span class="line">DoCompactionWork() &#123;</span><br><span class="line">	<span class="comment">//对所有传入的sstfile中的键值使用归并排序合并</span></span><br><span class="line">	Iterator* input = versions_-&gt;MakeInputIterator(compact-&gt;compaction);</span><br><span class="line">	input-&gt;SeekToFirst();</span><br><span class="line">	<span class="comment">//遍历所有key</span></span><br><span class="line">	<span class="keyword">for</span> ( input-&gt;Valid() ) &#123;</span><br><span class="line">		<span class="keyword">bool</span> drop = <span class="literal">false</span>;</span><br><span class="line">		 <span class="keyword">if</span> (!ParseInternalKey(key, &amp;ikey)) &#123;</span><br><span class="line">      		<span class="comment">// Do not hide error keys</span></span><br><span class="line">     		current_user_key.clear();</span><br><span class="line">      		has_current_user_key = <span class="literal">false</span>;</span><br><span class="line">     		last_sequence_for_key = kMaxSequenceNumber;</span><br><span class="line">    	&#125; <span class="keyword">else</span> &#123;</span><br><span class="line">    		<span class="keyword">if</span> (!has_current_user_key ||</span><br><span class="line">          user_comparator()-&gt;Compare(ikey.user_key,</span><br><span class="line">                                     Slice(current_user_key)) != <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="comment">//这个user_key是第一次出现</span></span><br><span class="line">        current_user_key.assign(ikey.user_key.data(), ikey.user_key.size());</span><br><span class="line">        has_current_user_key = <span class="literal">true</span>;</span><br><span class="line">        last_sequence_for_key = kMaxSequenceNumber;</span><br><span class="line">      	&#125;</span><br><span class="line"></span><br><span class="line">      	<span class="keyword">if</span> (last_sequence_for_key &lt;= compact-&gt;smallest_snapshot) &#123;</span><br><span class="line">        <span class="comment">// last_sequence_for_key比快照中的key还旧，需要删除</span></span><br><span class="line">        drop = <span class="literal">true</span>;    <span class="comment">// rule A</span></span><br><span class="line">      &#125; <span class="keyword">else</span> <span class="keyword">if</span> (ikey.type == kTypeDeletion &amp;&amp;</span><br><span class="line">                 ikey.sequence &lt;= compact-&gt;smallest_snapshot &amp;&amp;</span><br><span class="line">                 compact-&gt;compaction-&gt;IsBaseLevelForKey(ikey.user_key)) &#123;</span><br><span class="line">       			<span class="comment">// 一个被标记为删除的key满足如下所有条件，才可删除：</span></span><br><span class="line">        		<span class="comment">// (1) 更高层不会出现该key</span></span><br><span class="line">        		<span class="comment">// (2) 更低层的key的sequence number更小</span></span><br><span class="line">        		<span class="comment">// (3) 符合如上规则A</span></span><br><span class="line">        		drop = <span class="literal">true</span>;</span><br><span class="line">      		&#125;</span><br><span class="line"></span><br><span class="line">      		last_sequence_for_key = ikey.sequence;</span><br><span class="line">    	&#125;</span><br><span class="line"></span><br><span class="line">	 	<span class="comment">//如果该key不需要删除，则写入新的sstfile中</span></span><br><span class="line">	 	<span class="keyword">if</span>(!drop) &#123;</span><br><span class="line">	 		<span class="comment">//如果当前output file为空则打开一个output file</span></span><br><span class="line"></span><br><span class="line">	 		<span class="keyword">if</span> (compact-&gt;builder-&gt;NumEntries() == <span class="number">0</span>) &#123;</span><br><span class="line">        		compact-&gt;current_output()-&gt;smallest.DecodeFrom(key);</span><br><span class="line">     		&#125;</span><br><span class="line">      		compact-&gt;current_output()-&gt;largest.DecodeFrom(key);</span><br><span class="line">      		compact-&gt;builder-&gt;Add(key, input-&gt;value());</span><br><span class="line"></span><br><span class="line">      		<span class="comment">//如果当前output file过大，则关闭它</span></span><br><span class="line">	 	&#125;</span><br><span class="line">	 	input-&gt;Next();</span><br><span class="line">	 &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>其中，LogAndApply是根据VersionEdit来生成新的version，并将新生成的version数据append到manifest中来进行持久化存储，这部分会在下节展开。</p>
<h2 id="Version"><a href="#Version" class="headerlink" title="Version"></a>Version</h2><p>Version机制作用简要概括如下：</p>
<ul>
<li>维护sstfile的索引信息，包括每层由哪些文件，每个文件的key range等</li>
<li>根据sstfile信息，生成compaction相关的信息</li>
<li>在每次compaction后，将元数据持久化至manifest中，供DB启动或恢复时加载</li>
<li>维护版本信息，在此基础之上生成快照</li>
</ul>
<p>Version机制涉及到数据结构主要有三个：<code>Version</code>，<code>VersionEdit</code>，<code>VersionSet</code>，其中每个Version都记录了当前sstfile的索引信息，每次compaction后都会生成一个新的version，而这次compaction的文件变化情况就是用VersionEdit来记录的，简单来说就是：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">version0 + versionedit = version1</span><br></pre></td></tr></table></figure>
<p>此外，为了支持快照及MVCC，老的version不会马上就删除，而是通过VersionSet来管理，VersionSet中所有的version是通过双向链表来连接的，这样可以方便地查找各个version对应的数据，简单来说就是：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">versionset = version0 + version1 + ... + currentversion</span><br></pre></td></tr></table></figure>
<p>如下所示：</p>
<p><img src="/images/level/pic2.png" alt=""></p>
<h3 id="VersionEdit"><a href="#VersionEdit" class="headerlink" title="VersionEdit"></a>VersionEdit</h3><p>VersionEdit的主要结构如下，它记录了一次compaction后sstfile的变化信息，包括新增哪些文件、删除哪些文件、某个level参与compaction的最大key是什么：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">//一个VersionEdit总是与一次compaction相关</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">VersionEdit</span> &#123;</span></span><br><span class="line">  <span class="comment">//要删除的文件集合</span></span><br><span class="line">  <span class="keyword">typedef</span> <span class="built_in">std</span>::<span class="built_in">set</span>&lt; <span class="built_in">std</span>::pair&lt;<span class="keyword">int</span>, <span class="keyword">uint64_t</span>&gt; &gt; DeletedFileSet;</span><br><span class="line">  <span class="comment">//要新增的文件集合</span></span><br><span class="line">  <span class="built_in">std</span>::<span class="built_in">vector</span>&lt; <span class="built_in">std</span>::pair&lt;<span class="keyword">int</span>, FileMetaData&gt; &gt; new_files_;</span><br><span class="line">  <span class="comment">//记录此次compaction时，某层参与的最大key，下次compaction时会选择该key的后一个文件来进行compaction</span></span><br><span class="line">  <span class="built_in">std</span>::<span class="built_in">vector</span>&lt; <span class="built_in">std</span>::pair&lt;<span class="keyword">int</span>, InternalKey&gt; &gt; compact_pointers_;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">void</span> <span class="title">SetCompactPointer</span><span class="params">(<span class="keyword">int</span> level, <span class="keyword">const</span> InternalKey&amp; key)</span> </span>&#123;&#125;;</span><br><span class="line"></span><br><span class="line">  <span class="function"><span class="keyword">void</span> <span class="title">AddFile</span><span class="params">(<span class="keyword">int</span> level, <span class="keyword">uint64_t</span> file,</span></span></span><br><span class="line"><span class="function"><span class="params">               <span class="keyword">uint64_t</span> file_size,</span></span></span><br><span class="line"><span class="function"><span class="params">               <span class="keyword">const</span> InternalKey&amp; smallest,</span></span></span><br><span class="line"><span class="function"><span class="params">               <span class="keyword">const</span> InternalKey&amp; largest)</span> </span>&#123;&#125; ;</span><br><span class="line">   </span><br><span class="line">  <span class="function"><span class="keyword">void</span> <span class="title">DeleteFile</span><span class="params">(<span class="keyword">int</span> level, <span class="keyword">uint64_t</span> file)</span> </span>&#123;&#125;;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<h3 id="Version-1"><a href="#Version-1" class="headerlink" title="Version"></a>Version</h3><p>LevelDB是通过version来记录数据库是有哪些sst文件组成的，每次compaction后都会生成新的version，version是LevelDB实现快照和MVCC的基础，它的主要结构如下：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Version</span> &#123;</span></span><br><span class="line">	VersionSet* vset_; </span><br><span class="line">	<span class="comment">//更旧的版本</span></span><br><span class="line">	Version* next_;</span><br><span class="line">	<span class="comment">//更新的版本</span></span><br><span class="line">	Version* prev_;</span><br><span class="line">	<span class="comment">//该version的引用数，初始为1，读取或者创建快照都会增加引用数</span></span><br><span class="line">	<span class="keyword">int</span> refs_;</span><br><span class="line"></span><br><span class="line">	<span class="comment">//当前sst文件的索引信息</span></span><br><span class="line">	<span class="built_in">std</span>::<span class="built_in">vector</span>&lt;FileMetaData*&gt; files_[config::kNumLevels];</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>其中一个很重要的成员是引用数。。在一次compaction后，需要删除的sst文件并不会立马删除，因为此时可能会有读请求或者快照仍需要查找旧的文件来获取数据，这都是通过引用计数来控制的。一个version在生成时默认引用数为1，引用数变为0的时候便可以删除，当读请求释放或者该version不是最新版本时，refs_都会减1。总的来说，LevelDB的MVCC和快照机制是由一下几个部分组成：</p>
<ul>
<li>sst文件是不可变的，在compaction的时候也不影响read</li>
<li>每个key在内部存储时都会带上SequenceNumber，打快照时只需记录对应的SequenceNumber即可</li>
<li>version通过引用计数来保证资源的有效性，防止write影响read或者影响快照</li>
</ul>
<h3 id="VersionSet"><a href="#VersionSet" class="headerlink" title="VersionSet"></a>VersionSet</h3><p>VersionSet管理系统当前所有version，并负责这些元数据的持久化，其中最重要的方法就是<code>LogAndApply</code>，在每次version发生变化时该方法都会被调用，根据VersionEdit生成一个最新的Version，并 插入链表头部，持久化存储在manifest中，如下：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line">LogAndApply(VersionEdit* edit, port::Mutex* mu) &#123;</span><br><span class="line">	Version* v = <span class="keyword">new</span> Version(<span class="keyword">this</span>);</span><br><span class="line">  	&#123;</span><br><span class="line">    	<span class="function">Builder <span class="title">builder</span><span class="params">(<span class="keyword">this</span>, current_)</span></span>;</span><br><span class="line">    	<span class="comment">//将edit生效，记录在builder中</span></span><br><span class="line">    	builder.Apply(edit);</span><br><span class="line">    	<span class="comment">//生成新的version</span></span><br><span class="line">    	builder.SaveTo(v);</span><br><span class="line">  	&#125;</span><br><span class="line">  	Finalize(v);</span><br><span class="line"></span><br><span class="line">  	<span class="comment">//创建新的manifest文件</span></span><br><span class="line">  	<span class="keyword">if</span> (descriptor_log_ == <span class="literal">NULL</span>) &#123;</span><br><span class="line">    <span class="comment">// No reason to unlock *mu here since we only hit this path in the</span></span><br><span class="line">    <span class="comment">// first call to LogAndApply (when opening the database).</span></span><br><span class="line">    assert(descriptor_file_ == <span class="literal">NULL</span>);</span><br><span class="line">    new_manifest_file = DescriptorFileName(dbname_, manifest_file_number_);</span><br><span class="line">    edit-&gt;SetNextFile(next_file_number_);</span><br><span class="line">    s = env_-&gt;NewWritableFile(new_manifest_file, &amp;descriptor_file_);</span><br><span class="line">    <span class="keyword">if</span> (s.ok()) &#123;</span><br><span class="line">      descriptor_log_ = <span class="keyword">new</span> <span class="built_in">log</span>::Writer(descriptor_file_);</span><br><span class="line">      s = WriteSnapshot(descriptor_log_);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="comment">//写入manifest时候，可以释放锁，让其他写入线程能进去队列排队</span></span><br><span class="line">  &#123;</span><br><span class="line">    mu-&gt;Unlock();</span><br><span class="line"></span><br><span class="line">    <span class="comment">// Write new record to MANIFEST log</span></span><br><span class="line">    <span class="comment">//将变化写入manifest中</span></span><br><span class="line">    <span class="keyword">if</span> (s.ok()) &#123;</span><br><span class="line">      <span class="built_in">std</span>::<span class="built_in">string</span> record;</span><br><span class="line">      edit-&gt;EncodeTo(&amp;record);</span><br><span class="line">      s = descriptor_log_-&gt;AddRecord(record);</span><br><span class="line">      <span class="keyword">if</span> (s.ok()) &#123;</span><br><span class="line">        s = descriptor_file_-&gt;Sync();</span><br><span class="line">      &#125;</span><br><span class="line">      <span class="keyword">if</span> (!s.ok()) &#123;</span><br><span class="line">        Log(options_-&gt;info_log, <span class="string">"MANIFEST write: %s\n"</span>, s.ToString().c_str());</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">// If we just created a new descriptor file, install it by writing a</span></span><br><span class="line">    <span class="comment">// new CURRENT file that points to it.</span></span><br><span class="line">    <span class="comment">//将current文件指向最新的manifest文件</span></span><br><span class="line">    <span class="keyword">if</span> (s.ok() &amp;&amp; !new_manifest_file.empty()) &#123;</span><br><span class="line">      s = SetCurrentFile(env_, dbname_, manifest_file_number_);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    mu-&gt;Lock();</span><br><span class="line">  &#125;</span><br><span class="line"></span><br><span class="line">  <span class="keyword">if</span>(s.ok()) &#123;</span><br><span class="line">  	<span class="comment">//将版本v插入头部，使current_指向该版本</span></span><br><span class="line">  	AppendVersion(v);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="触发机制"><a href="#触发机制" class="headerlink" title="触发机制"></a>触发机制</h2><p>LevelDB中总共有以下几种情况会出发compaction：</p>
<ul>
<li>memtable达到阈值时会出发minor compaction</li>
<li>手动触发：系统提供结构供用户指定key range及level来出发compaction，默认情况下，手动触发的compaction比自动触发的高</li>
<li>文件数触发：由于level 0中的文件间key range可能存在重叠，所以需要严格控制该层的文件数，该层的文件数大于阈值的时候并发触发major compaction</li>
<li>容量触发：level 0之上的文件需要严格控制容量，提高查询效率和避免过大的数据参与compaction，所以当level 0上某层的总数据量超过阈值时，便会触发major compaction</li>
<li>seek触发：系统在查找Key时会记录查找次数，由于每次查找都会消耗额外的IO，当查找次数过多时，对应的IO消耗会大于一次compaction所带来的IO，此时系统会触发compaction来降低某些key的查找次数</li>
</ul>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><p><a href="http://catkang.github.io/2017/02/03/leveldb-version.html" target="_blank" rel="noopener">庖丁解LevelDB之版本控制</a></p>
<p><a href="https://draveness.me/bigtable-leveldb" target="_blank" rel="noopener">浅析 Bigtable 和 LevelDB 的实现</a></p>
<p><a href="http://bean-li.github.io/leveldb-version/" target="_blank" rel="noopener">leveldb之Version VersionEdit and VersionSet</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2019/01/24/leveldb-file-format/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Leeshine">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Leesine's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/01/24/leveldb-file-format/" itemprop="url">LevelDB之文件格式</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-01-24T21:08:30+08:00">
                2019-01-24
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>LevelDB中主要有以下几种文件：<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">enum</span> FileType &#123;</span><br><span class="line">  kLogFile,</span><br><span class="line">  kDBLockFile,</span><br><span class="line">  kTableFile,</span><br><span class="line">  kDescriptorFile,</span><br><span class="line">  kCurrentFile,</span><br><span class="line">  kTempFile,</span><br><span class="line">  kInfoLogFile  <span class="comment">// Either the current one, or an old one</span></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></p>
<p>对应的文件作用如下：</p>
<ul>
<li>kLogFile：WAL日志文件，文件名为[0-9]+.log</li>
<li>kDBLockFile：db锁文件，文明名为LOCK，通过LOCK文件加文件锁（flock）来实现只有一个实例能操作db</li>
<li>kTableFile：sstable文件，文件名为[0-9]+.sst</li>
<li>kDescriptorFile：db元数据文件，存储系统中version信息，文件名为MANIFEST-[0-9]+，每当db发生compaction时，对应的versionedit会记录到descriptor文件中</li>
<li>kCurrentFile：记录当前使用的descriptor文件名，文件名为CURRENT</li>
<li>kTempFile：临时文件，db在修复过程中会产生临时文件，文件名为[0-9]+.dbtmp</li>
<li>kInfoLogFile：db运行过程中的日志文件，文件名为LOG</li>
</ul>
<p>下面主要来分析kLogFile文件、kTableFile。</p>
<h2 id="kLogFile"><a href="#kLogFile" class="headerlink" title="kLogFile"></a>kLogFile</h2><p>kLogFile是以block为单位组织的，除了文件结尾的block外，每个block的大小为32KB。每个block由若干填入record组成，如下所示：<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Each block consists of a sequence of records:</span><br><span class="line"></span><br><span class="line">    block := record* trailer?</span><br><span class="line">    record :=</span><br><span class="line">      checksum: uint32     <span class="comment">// type及data部分数据的校验值，大小为4B，用小端序存储</span></span><br><span class="line">      length: uint16       <span class="comment">// data部分的长度，大小为2B</span></span><br><span class="line">      type: uint8          <span class="comment">// FULL, FIRST, MIDDLE, LAST中的一个，大小为1B</span></span><br><span class="line">      data: uint8[length]  <span class="comment">//存储实际数据</span></span><br></pre></td></tr></table></figure></p>
<p>block的示意图如下：</p>
<p><img src="/images/level/pic3.png" alt=""></p>
<p>每个record的示意图如下：</p>
<p><img src="/images/level/pic4.png" alt=""></p>
<p>一个record不会从block的最后6B的位置开始写入（因为一个record至少为7B），所以一个block可能会以trailer结尾，此部分位置会全部填0，读取该block时该部分数据会被跳过。由于每个block的大小固定，一条wal日志可能需要被切分到多个block中的record中存储，type这个字段记录的便是这个record的类型，目前只有上文所列的四种类型。FULL表示当前record存储的是一条完整的日志，FIRST、MIDDLE、LAST分别代表一条日志的头部、中部、尾部三个部分，通过多个record的拼接可还原出一条完整的日志。</p>
<h3 id="log写入"><a href="#log写入" class="headerlink" title="log写入"></a>log写入</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line">AddRecord(<span class="keyword">const</span> Slice&amp; slice) &#123;</span><br><span class="line">  </span><br><span class="line">  Status s;</span><br><span class="line">  <span class="keyword">bool</span> begin = <span class="literal">true</span>;</span><br><span class="line">  <span class="keyword">do</span> &#123;</span><br><span class="line">    <span class="keyword">const</span> <span class="keyword">int</span> leftover = kBlockSize - block_offset_;</span><br><span class="line">    assert(leftover &gt;= <span class="number">0</span>);</span><br><span class="line">    <span class="keyword">if</span> (leftover &lt; kHeaderSize) &#123;</span><br><span class="line">      <span class="comment">// 如果当前block剩余空间小于7B，则在block尾部填0后切换至新的block</span></span><br><span class="line">      <span class="keyword">if</span> (leftover &gt; <span class="number">0</span>) &#123;</span><br><span class="line">        <span class="comment">// 尾部填0</span></span><br><span class="line">        assert(kHeaderSize == <span class="number">7</span>);</span><br><span class="line">        dest_-&gt;Append(Slice(<span class="string">"\x00\x00\x00\x00\x00\x00"</span>, leftover));</span><br><span class="line">      &#125;</span><br><span class="line">      block_offset_ = <span class="number">0</span>;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">const</span> <span class="keyword">size_t</span> avail = kBlockSize - block_offset_ - kHeaderSize;</span><br><span class="line">    <span class="keyword">const</span> <span class="keyword">size_t</span> fragment_length = (left &lt; avail) ? left : avail;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//填入该record的type</span></span><br><span class="line">    RecordType type;</span><br><span class="line">    <span class="keyword">const</span> <span class="keyword">bool</span> end = (left == fragment_length);</span><br><span class="line">    <span class="keyword">if</span> (begin &amp;&amp; end) &#123;</span><br><span class="line">      type = kFullType;</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (begin) &#123;</span><br><span class="line">      type = kFirstType;</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (end) &#123;</span><br><span class="line">      type = kLastType;</span><br><span class="line">    &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">      type = kMiddleType;</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//写入record</span></span><br><span class="line">    s = EmitPhysicalRecord(type, ptr, fragment_length);</span><br><span class="line">    ptr += fragment_length;</span><br><span class="line">    left -= fragment_length;</span><br><span class="line">    begin = <span class="literal">false</span>;</span><br><span class="line">  &#125; <span class="keyword">while</span> (s.ok() &amp;&amp; left &gt; <span class="number">0</span>);</span><br><span class="line">  <span class="keyword">return</span> s;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h3 id="log读取"><a href="#log读取" class="headerlink" title="log读取"></a>log读取</h3><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line">ReadRecord(Slice* record, <span class="built_in">std</span>::<span class="built_in">string</span>* scratch) &#123;</span><br><span class="line">  Slice fragment;</span><br><span class="line">  <span class="keyword">while</span> (<span class="literal">true</span>) &#123;</span><br><span class="line">    <span class="keyword">const</span> <span class="keyword">unsigned</span> <span class="keyword">int</span> record_type = ReadPhysicalRecord(&amp;fragment);</span><br><span class="line">    <span class="comment">//计算该block中下个实际record的偏移值</span></span><br><span class="line">    <span class="keyword">uint64_t</span> physical_record_offset =</span><br><span class="line">        end_of_buffer_offset_ - buffer_.size() - kHeaderSize - fragment.size();</span><br><span class="line"></span><br><span class="line">    <span class="keyword">switch</span> (record_type) &#123;</span><br><span class="line">      <span class="keyword">case</span> kFullType:</span><br><span class="line">        <span class="comment">//如果读取的record是完整的一条记录，则直接返回读取到的数据</span></span><br><span class="line">        scratch-&gt;clear();</span><br><span class="line">        *record = fragment;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line"></span><br><span class="line">      <span class="keyword">case</span> kFirstType:</span><br><span class="line">       </span><br><span class="line">        <span class="comment">//读取到的是第一个record，存储在scratch中，继续读取</span></span><br><span class="line">        scratch-&gt;assign(fragment.data(), fragment.size());</span><br><span class="line">        in_fragmented_record = <span class="literal">true</span>;</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line"></span><br><span class="line">      <span class="keyword">case</span> kMiddleType:</span><br><span class="line">        <span class="comment">//读取到中间record，拼接数据，继续读取</span></span><br><span class="line">        scratch-&gt;append(fragment.data(), fragment.size());</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line"></span><br><span class="line">      <span class="keyword">case</span> kLastType:</span><br><span class="line">       <span class="comment">//读取到最后一个record，拼接数据，继续读取</span></span><br><span class="line">        <span class="keyword">if</span> (!in_fragmented_record) &#123;</span><br><span class="line">          ReportCorruption(fragment.size(),</span><br><span class="line">                           <span class="string">"missing start of fragmented record(2)"</span>);</span><br><span class="line">        &#125; <span class="keyword">else</span> &#123;</span><br><span class="line">          scratch-&gt;append(fragment.data(), fragment.size());</span><br><span class="line">          *record = Slice(*scratch);</span><br><span class="line">          last_record_offset_ = prospective_record_offset;</span><br><span class="line">          <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">break</span>;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="kTableFile"><a href="#kTableFile" class="headerlink" title="kTableFile"></a>kTableFile</h2><p>kTableFile是db中持久化存储数据的文件，它也是以block的形式来组成文件，整体上看，它主要有数据block、元数据block组成，由于kTableFile文件尺寸可能较大，读取时如果从头扫描这个文件会造成读取效率低下，所以kTableFile文件中也存储data block及meta block的索引信息来加速读取，整体格式如下：<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&lt;beginning_of_file&gt;</span><br><span class="line">[data block <span class="number">1</span>]</span><br><span class="line">[data block <span class="number">2</span>]</span><br><span class="line">...</span><br><span class="line">[data block N]</span><br><span class="line">[meta block <span class="number">1</span>]</span><br><span class="line">...</span><br><span class="line">[meta block K]</span><br><span class="line">[metaindex block]</span><br><span class="line">[index block]</span><br><span class="line">[Footer]        (fixed size; starts at file_size - <span class="keyword">sizeof</span>(Footer))</span><br><span class="line">&lt;end_of_file&gt;</span><br></pre></td></tr></table></figure></p>
<p>整体示意图如下：</p>
<p><img src="/images/level/pic5.png" alt=""></p>
<p>其中，data_block存储的实际kv数据，index block中保存的是每个data block的last key及其在文件中的索引（偏移量，大小），当前版本中，meta block及metaindex block均未实现。Footer是文件尾部固定长度的块，存储的是metaindex block及index block的索引信息。<br>每个data block在生成时，会在其尾部存储1B的type和4B的crc，分别记录该block的压缩类型及数据校验值。Block中的每个record（rentry）存储了一条kv数据，由于key是连续的，系统会key采用前缀压缩的方式来减少所需存储空间，只需存储当前key的不同部分，前缀可以从之前的key中获取出来。Block的结构如下:</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">Block := entry* </span><br><span class="line">		 trailer </span><br><span class="line">		 type <span class="comment">//压缩类型，1B</span></span><br><span class="line">		 crc <span class="comment">// 数据校验值，4B</span></span><br><span class="line">entry := </span><br><span class="line">		shared_bytes <span class="comment">// key中共享前缀的长度</span></span><br><span class="line">		unshared_bytes <span class="comment">// key中非共享前缀的长度</span></span><br><span class="line">		value_length <span class="comment">// value的长度</span></span><br><span class="line">		key_dalta <span class="comment">// key非共享部分内容</span></span><br><span class="line">		value <span class="comment">// value数据</span></span><br></pre></td></tr></table></figure>
<p>例如第一个key为<code>sam</code>，第二个key为<code>samon</code>，则第二条记录只需存储<code>on</code>这部分数据，前缀可以根据前一个key获取出来，此时该entry对应的各部分如下：<br><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">shared_bytes: <span class="number">3</span></span><br><span class="line">unshared_bytes: <span class="number">2</span></span><br><span class="line">key_dalta: on</span><br></pre></td></tr></table></figure></p>
<p>通过这种前缀压缩的方式可以降低所需存储空间。此外，如果一个block完全按照前文所述逻辑进行压缩，每次查找key的时候都要从头开始遍历，这样的查找效率可能较低。所以系统进一步细化了粒度，采用分段压缩，每个段内的key都以第一个key开始做前缀压缩，这第一个key就被称作重启点，block中所有重启点的偏移值和数量都会记录在trailer中。</p>
<h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul>
<li>淘宝leveldb的实现</li>
<li><a href="http://catkang.github.io/2017/01/17/leveldb-data.html" target="_blank" rel="noopener">庖丁解LevelDB之数据存储</a></li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/12/18/linux-performance-analysis-60s/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Leeshine">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Leesine's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/12/18/linux-performance-analysis-60s/" itemprop="url">Linux性能分析60秒</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-12-18T21:05:05+08:00">
                2018-12-18
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <blockquote>
<p>在本文中，我们来看在调查某个主机的性能问题时，前60S内应该首先查看哪些信息，从而快速了解整个主机的运行状况。</p>
</blockquote>
<p>在前60S内，通过运行以下10个命令，我们可以对系统的资源使用情况、进程运行状况有个整体了解</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">uptime</span><br><span class="line">dmesg</span><br><span class="line">vmstat 1</span><br><span class="line">mpstat -P ALL 1</span><br><span class="line">pidstat 1</span><br><span class="line">iostat -xz 1</span><br><span class="line">free -m</span><br><span class="line">sar -n DEV 1</span><br><span class="line">sar -n TCP,ETCP 1</span><br><span class="line">top</span><br></pre></td></tr></table></figure>
<h2 id="uptime"><a href="#uptime" class="headerlink" title="uptime"></a>uptime</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ uptime </span><br><span class="line">21:43:21 up 78 days,  3:07,  2 users,  load average: 3.71, 3.08, 3.13</span><br></pre></td></tr></table></figure>
<p>uptime可以使我们快速了解系统的整体负载信息，以上输出中显示的信息依次为：系统当前时间、已运行时间、 登陆用户数、平均负载，其中平均负载这里的三个数字分别表示过去1分钟、5分钟、15分钟内CPU的负载情况。对于CPU的单个核心来说，负载为1.0则说明CPU负载已经较高，没有剩余的资源了，如果长期保持在这个负载的话，则容易造成请求的积压，对于多核CPU，则该值是表示所有核的累加值。在实际定位过程中，主要是以15分钟内CPU的负载数为准，如果15分钟内CPU的负载仍然较高，那就需要注意了</p>
<h2 id="dmesg"><a href="#dmesg" class="headerlink" title="dmesg"></a>dmesg</h2><p>dmesg是用来显示内核环缓冲区的内容，内核将各种消息都存放在这里，内核环缓冲区的消息对于诊断系统问题很有用。例如我们可以通过dmesg查看是否有进程因为OOM被杀死、是否有TCP请求被丢弃等</p>
<h2 id="vmstat"><a href="#vmstat" class="headerlink" title="vmstat"></a>vmstat</h2><p>vmstat可对操作系统的虚拟内存、进程、CPU活动进行监控，如下所示：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">$ vmstat 1</span><br><span class="line">procs -----------memory---------- ---swap-- -----io---- -system-- ------cpu-----</span><br><span class="line"> r  b   swpd   free   buff  cache   si   so    bi    bo   in   cs us sy id wa st</span><br><span class="line">11  1 2039544 15472068   5000 2144664    0    0   757   262    0    0  5  2 90  4  0</span><br><span class="line">13  1 2039328 15674144   5020 2139396 1248    0 10448    44 89482 181158 13 38 44  5  0</span><br><span class="line"> 7  1 2039004 16007556   5020 2122564 1760    0  7672    12 104794 213528 14 40 41  4  0</span><br><span class="line"> 3  2 2038660 16180976   5040 2110112 1884    0  3468    20 100660 200327 19 39 37  5  0</span><br><span class="line"> 6  2 2038464 16486160   5040 2094924  928    0  7688    12 90962 182643 15 38 43  5  0</span><br><span class="line"> 2  2 2038200 16674132   5040 2090216 1060    0 10856    12 56284 108656 14 29 51  5  0</span><br><span class="line"> 2  1 2037976 16817976   5052 2091832 1152    0 12184 10828 47027 85099 11 24 59  6  0</span><br></pre></td></tr></table></figure>
<p>以上输出中，主要关注如下列：</p>
<ul>
<li>r: 运行队列中的进程数量，即占用CPU的进程数。如果CPU单核上超过3个进程，那么CPU的负载就较高了</li>
<li>swap: 使用的虚拟内存大小，如果此值较高，说明内存可能不足</li>
<li>free: 可用内存大小</li>
<li>si,so:  每秒从交换区写入内存的大小，每秒从内存写入交换区的大小</li>
<li>us,sy,id,wa,st: 用户空间时间、系统空间时间、空闲时间、等待IO时间、被强制等待CPU的时间。如果us+sy所占的比例较高的话，则说明CPU负载较高，如果wa的比例较高，则说明磁盘可能存在瓶颈</li>
</ul>
<h2 id="mpstat"><a href="#mpstat" class="headerlink" title="mpstat"></a>mpstat</h2><p>mpstat是CPU的实时监控工具，可以检测CPU中每个核的运行状况，如下所示：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line">$ mpstat -P ALL 1</span><br><span class="line">Linux 3.10.107-1-tlinux2-0046 (100.98.49.234) 	12/18/2018 	_x86_64_	(12 CPU)</span><br><span class="line"></span><br><span class="line">07:52:07 PM  CPU    %usr   %nice    %sys %iowait    %irq   %soft  %steal  %guest  %gnice   %idle</span><br><span class="line">07:52:08 PM  all    3.17    0.00    0.92    9.19    0.00    0.17    0.00    0.00    0.00   86.55</span><br><span class="line">07:52:08 PM    0    3.03    0.00    2.02   49.49    0.00    0.00    0.00    0.00    0.00   45.45</span><br><span class="line">07:52:08 PM    1    6.00    0.00    2.00   45.00    0.00    1.00    0.00    0.00    0.00   46.00</span><br><span class="line">07:52:08 PM    2    2.00    0.00    1.00   13.00    0.00    0.00    0.00    0.00    0.00   84.00</span><br><span class="line">07:52:08 PM    3    3.00    0.00    0.00    2.00    0.00    0.00    0.00    0.00    0.00   95.00</span><br><span class="line">07:52:08 PM    4    1.98    0.00    0.99    0.99    0.00    0.00    0.00    0.00    0.00   96.04</span><br><span class="line">07:52:08 PM    5   18.00    0.00    3.00    0.00    0.00    0.00    0.00    0.00    0.00   79.00</span><br><span class="line">07:52:08 PM    6    3.06    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00   96.94</span><br><span class="line">07:52:08 PM    7    1.01    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00   98.99</span><br><span class="line">07:52:08 PM    8    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00  100.00</span><br><span class="line">07:52:08 PM    9    1.01    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00   98.99</span><br><span class="line">07:52:08 PM   10    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00    0.00  100.00</span><br><span class="line">07:52:08 PM   11    1.00    0.00    1.00    0.00    0.00    0.00    0.00    0.00    0.00   98.00</span><br></pre></td></tr></table></figure>
<p>通过vmstat可以获取CPU的综合使用情况，而通过mpstat可以获取每个CPU核心的使用情况，某些糟糕的程序可能会一直只使用一个CPU核心，而不是运行在所有处理器上，从而导致某个CPU核心负载很高，其他CPU资源却是空闲的。通过mpstat便可诊断这类问题</p>
<h2 id="pidstat"><a href="#pidstat" class="headerlink" title="pidstat"></a>pidstat</h2><p>pidstat同top命令类似，用以监控全部或者指定进程的CPU、内存等资源的占用情况，它会将这些信息滚动打印，如下所示：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line">$ pidstat 1</span><br><span class="line">Linux 3.10.107-1-tlinux2-0046 (100.98.49.234) 	12/18/2018 	_x86_64_	(12 CPU)</span><br><span class="line"></span><br><span class="line">07:59:50 PM   UID       PID    %usr %system  %guest    %CPU   CPU  Command</span><br><span class="line">07:59:51 PM     0   1008095    0.00    0.99    0.00    0.99     9  kworker/9:2</span><br><span class="line">07:59:51 PM     0   1359487    0.00    0.99    0.00    0.99    10  ceph-osd</span><br><span class="line">07:59:51 PM     0   1360110    2.97    1.98    0.00    4.95     4  ceph-osd</span><br><span class="line">07:59:51 PM     0   1361355    1.98    1.98    0.00    3.96    10  ceph-osd</span><br><span class="line">07:59:51 PM     0   1362096    0.00    0.99    0.00    0.99     2  ceph-osd</span><br><span class="line">07:59:51 PM     0   1362981    0.99    0.00    0.00    0.99     5  ceph-osd</span><br><span class="line">07:59:51 PM     0   1365565    1.98    1.98    0.00    3.96     4  ceph-osd</span><br><span class="line">07:59:51 PM     0   1368403    2.97    1.98    0.00    4.95     5  ceph-osd</span><br><span class="line">07:59:51 PM     0   2070599    1.98    2.97    0.00    4.95     5  sap1002</span><br><span class="line">07:59:51 PM     0   2070612    0.00    0.99    0.00    0.99     5  sap1008</span><br><span class="line">07:59:51 PM     0   2430524    0.00    0.99    0.00    0.99     1  pidstat</span><br><span class="line"></span><br><span class="line">07:59:51 PM   UID       PID    %usr %system  %guest    %CPU   CPU  Command</span><br><span class="line">07:59:52 PM     0        21    0.00    1.00    0.00    1.00     3  rcu_sched</span><br><span class="line">07:59:52 PM     0       195    0.00    1.00    0.00    1.00     0  kworker/0:1H</span><br><span class="line">07:59:52 PM     0     14132    1.00    1.00    0.00    2.00     8  safe_TsysAgent.</span><br><span class="line">07:59:52 PM     0   1358777    1.00    0.00    0.00    1.00     4  ceph-osd</span><br><span class="line">07:59:52 PM     0   1359487    1.00    0.00    0.00    1.00    10  ceph-osd</span><br><span class="line">07:59:52 PM     0   1360110    5.00    0.00    0.00    5.00     4  ceph-osd</span><br><span class="line">07:59:52 PM     0   1361355    2.00    2.00    0.00    4.00    10  ceph-osd</span><br><span class="line">07:59:52 PM     0   1362981    0.00    1.00    0.00    1.00     5  ceph-osd</span><br><span class="line">07:59:52 PM     0   1363880    1.00    0.00    0.00    1.00     5  ceph-osd</span><br><span class="line">07:59:52 PM     0   1364665    1.00    1.00    0.00    2.00    10  ceph-osd</span><br><span class="line">07:59:52 PM     0   1365565    3.00    0.00    0.00    3.00     4  ceph-osd</span><br><span class="line">07:59:52 PM     0   1366476    1.00    0.00    0.00    1.00     4  ceph-osd</span><br><span class="line">07:59:52 PM     0   1367460    1.00    1.00    0.00    2.00     4  ceph-osd</span><br><span class="line">07:59:52 PM     0   1368403    3.00    2.00    0.00    5.00     5  ceph-osd</span><br><span class="line">07:59:52 PM     0   1646795    0.00    1.00    0.00    1.00    10  kworker/10:1</span><br><span class="line">07:59:52 PM     0   2417476    1.00    0.00    0.00    1.00     7  fdbcli</span><br><span class="line">07:59:52 PM     0   2430524    0.00    1.00    0.00    1.00     1  pidstat</span><br></pre></td></tr></table></figure>
<h2 id="iostat"><a href="#iostat" class="headerlink" title="iostat"></a>iostat</h2><p>iostat用以监控系统中的IO状态，如下所示：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">$ iostat -xz 1</span><br><span class="line">Linux 3.10.107-1-tlinux2-0046 (100.98.49.234) 	12/18/2018 	_x86_64_	(12 CPU)</span><br><span class="line"></span><br><span class="line">avg-cpu:  %user   %nice %system %iowait  %steal   %idle</span><br><span class="line">           4.84    0.00    1.81    3.57    0.00   89.78</span><br><span class="line"></span><br><span class="line">Device:         rrqm/s   wrqm/s     r/s     w/s    rkB/s    wkB/s avgrq-sz avgqu-sz   await r_await w_await  svctm  %util</span><br><span class="line">sda               0.06     3.95    0.31    9.31     6.25   190.85    40.97     0.31   31.39    0.36   32.44   3.41   3.28</span><br><span class="line">sdh               0.00     0.23    6.22    1.94   700.92   228.59   227.96     0.11   13.19   11.24   19.44   9.74   7.94</span><br><span class="line">sdm               0.00     0.28    7.77    2.40   875.65   284.36   228.15     0.14   13.44   11.11   20.99   9.64   9.80</span><br><span class="line">sdi               0.00     0.28    6.63    2.20   750.45   242.41   224.79     0.12   13.20   11.34   18.81   9.75   8.61</span><br><span class="line">sdk               0.00     0.30    7.66    2.27   871.22   276.49   231.28     0.13   13.44   11.06   21.49   9.64   9.57</span><br><span class="line">sdd               0.00     0.29    5.83    2.65   646.21   216.63   203.62     0.10   12.33   11.12   15.00   9.14   7.75</span><br><span class="line">sdl               0.00     0.24    5.96    1.92   676.90   220.14   227.71     0.10   12.91   10.96   18.95   9.54   7.52</span><br><span class="line">sdj               0.00     0.27    7.15    2.17   805.51   261.04   228.82     0.12   13.14   11.06   20.01   9.63   8.98</span><br><span class="line">sde               0.00     0.27    7.17    2.12   799.00   264.21   228.99     0.12   13.31   11.10   20.78   9.67   8.98</span><br><span class="line">sdc               0.00     0.29    6.81    2.25   772.16   249.00   225.44     0.12   13.38   11.16   20.10   9.63   8.73</span><br><span class="line">sdb               0.00     0.27    6.98    2.08   788.66   256.29   230.90     0.12   13.52   11.27   21.10   9.78   8.86</span><br><span class="line">sdf               0.00     0.21    5.35    1.76   607.02   197.17   226.41     0.09   12.69   11.06   17.65   9.61   6.82</span><br><span class="line">sdg               0.00     0.24    6.69    2.03   768.27   243.12   232.07     0.12   13.36   11.24   20.37   9.75   8.50</span><br></pre></td></tr></table></figure>
<p>各列的含义如下：</p>
<ul>
<li>r/s, w/s,rKB/s,wKB/s: 一秒内读次数、写次数、读数据大小、写数据大小</li>
<li>await: IO的平均响应时间，包括IO’的等待时间、服务时间，如果这个时间较长，则说明磁盘可能存在瓶颈。一般来说，这个时间应该小于5ms</li>
<li>svctm: IO的平均服务时间，如果该值比较接近await，则说明IO几乎没有等待时间</li>
<li>avgqu-sz:  IO的平均队列长度，如果该值超过1，则说明排队请求较多，磁盘可能存在瓶颈</li>
<li>%util: 磁盘用以IO操作的时间百分比，如果该值接近100%，则说明产生的IO请求太多，磁盘负载已经很高</li>
</ul>
<h2 id="free"><a href="#free" class="headerlink" title="free"></a>free</h2><p>free可以用以显示系统的内存使用状况，如下所示:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ free -m</span><br><span class="line">             total       used       free     shared    buffers     cached</span><br><span class="line">Mem:        245998      24545     221453         83         59        541</span><br><span class="line">-/+ buffers/cache:      23944     222053</span><br><span class="line">Swap:            0          0          0</span><br></pre></td></tr></table></figure>
<p>其中最后一行表示swap分区的使用信息，第二行是操作系统层面的内存使用情况，其中buffers是buffer缓存内存数（写缓存），cached是page cache使用的内存缓存数（读缓存），第三行是减去buffer、cache的已使用量和加上buffer、cache的空闲量，这是用户层面的统计信息，因为对于用户程序来说，buffers、cached占用的内存是可以立即重新分配，供用户程序使用的。</p>
<h2 id="sar"><a href="#sar" class="headerlink" title="sar"></a>sar</h2><p>sar是目前Linux上最为全部的系统性能分析工具之一，我们可以通过sar来查看网络吞吐状况，如下所示：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line">$ sar -n DEV 1</span><br><span class="line">Linux 3.10.107-1-tlinux2-0046 (100.98.49.234) 	12/18/2018 	_x86_64_	(12 CPU)</span><br><span class="line"></span><br><span class="line">08:37:57 PM     IFACE   rxpck/s   txpck/s    rxkB/s    txkB/s   rxcmp/s   txcmp/s  rxmcst/s</span><br><span class="line">08:37:58 PM     bond1   2215.00   2259.00   1621.38   1712.75      0.00      0.00      2.00</span><br><span class="line">08:37:58 PM      eth0   1305.00   1068.00    992.93    724.90      0.00      0.00      1.00</span><br><span class="line">08:37:58 PM      eth1    910.00   1191.00    628.45    987.85      0.00      0.00      1.00</span><br><span class="line">08:37:58 PM        lo      3.00      3.00      0.99      0.99      0.00      0.00      0.00</span><br><span class="line"></span><br><span class="line">08:37:58 PM     IFACE   rxpck/s   txpck/s    rxkB/s    txkB/s   rxcmp/s   txcmp/s  rxmcst/s</span><br><span class="line">08:37:59 PM     bond1   3327.00   3264.00   2411.48   2390.17      0.00      0.00      2.00</span><br><span class="line">08:37:59 PM      eth0   1889.00   1508.00   1377.83   1035.24      0.00      0.00      1.00</span><br><span class="line">08:37:59 PM      eth1   1438.00   1756.00   1033.66   1354.92      0.00      0.00      1.00</span><br><span class="line">08:37:59 PM        lo      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br><span class="line"></span><br><span class="line">08:37:59 PM     IFACE   rxpck/s   txpck/s    rxkB/s    txkB/s   rxcmp/s   txcmp/s  rxmcst/s</span><br><span class="line">08:38:00 PM     bond1   3025.00   3221.00   2189.47   2477.83      0.00      0.00      3.00</span><br><span class="line">08:38:00 PM      eth0   1914.00   1621.00   1412.42   1133.86      0.00      0.00      1.00</span><br><span class="line">08:38:00 PM      eth1   1111.00   1600.00    777.05   1343.97      0.00      0.00      2.00</span><br><span class="line">08:38:00 PM        lo      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span><br></pre></td></tr></table></figure>
<p>每列的含义如下：</p>
<ul>
<li>rxpck/s, txpck/s:  每秒接收、发送的包数目</li>
<li>rxkB/s, txkB/s:  每秒接收、发送的数据大小</li>
</ul>
<p>我们也可以通过sar来查看主机上TCP连接的状况，如下所示：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">$ sar -n TCP,ETCP 1</span><br><span class="line">Linux 3.13.0-49-generic (titanclusters-xxxxx)  07/14/2015    _x86_64_    (32 CPU)</span><br><span class="line"></span><br><span class="line">12:17:19 AM  active/s passive/s    iseg/s    oseg/s</span><br><span class="line">12:17:20 AM      1.00      0.00  10233.00  18846.00</span><br><span class="line"></span><br><span class="line">12:17:19 AM  atmptf/s  estres/s retrans/s isegerr/s   orsts/s</span><br><span class="line">12:17:20 AM      0.00      0.00      0.00      0.00      0.00</span><br><span class="line"></span><br><span class="line">12:17:20 AM  active/s passive/s    iseg/s    oseg/s</span><br><span class="line">12:17:21 AM      1.00      0.00   8359.00   6039.00</span><br><span class="line"></span><br><span class="line">12:17:20 AM  atmptf/s  estres/s retrans/s isegerr/s   orsts/s</span><br><span class="line">12:17:21 AM      0.00      0.00      0.00      0.00      0.00</span><br></pre></td></tr></table></figure>
<p>每列的含义如下：</p>
<ul>
<li>active/s:  本地每秒初始化的TCP连接数（通过connect（）连接远程服务器）</li>
<li>passive/s:  每秒远程连接的TCP数（通过accept（）接收远程连接）</li>
<li>retrans/s: 每秒TCP包重发次数，它通常是网络服务出现问题的标志（如出现丢包、网络负载太高等）</li>
</ul>
<h2 id="top"><a href="#top" class="headerlink" title="top"></a>top</h2><p>top命令可以简单快捷地统计系统中的资源使用情况、进程运行状况等，如下所示：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">$ top</span><br><span class="line">top - 20:47:16 up 79 days,  2:11, 10 users,  load average: 1.46, 2.02, 2.47</span><br><span class="line">Tasks: 325 total,   1 running, 324 sleeping,   0 stopped,   0 zombie</span><br><span class="line">%Cpu(s):  1.0 us,  0.5 sy,  0.0 ni, 98.4 id,  0.0 wa,  0.0 hi,  0.0 si,  0.0 st</span><br><span class="line">KiB Mem : 32281840 total,   393664 free, 19142128 used, 12746048 buff/cache</span><br><span class="line">KiB Swap:  2088956 total,   651716 free,  1437240 used.  8835108 avail Mem </span><br><span class="line"></span><br><span class="line">    PID USER      PR  NI    VIRT    RES    SHR S  %CPU %MEM     TIME+ COMMAND                                                                                                               </span><br><span class="line">1362981 root      20   0 1764960 693536   3476 S   6.7  2.1   1174:25 ceph-osd                                                                                                              </span><br><span class="line">2070599 root      20   0   20920  19808    680 S   6.7  0.1 814:04.35 sap1002                                                                                                               </span><br><span class="line">      1 root      20   0  193084   3432   1264 S   0.0  0.0  12:52.37 systemd                                                                                                               </span><br><span class="line">      2 root      20   0       0      0      0 S   0.0  0.0   0:03.77 kthreadd                                                                                                              </span><br><span class="line">      3 root      20   0       0      0      0 S   0.0  0.0   8:08.06 ksoftirqd/0                                                                                                           </span><br><span class="line">      5 root       0 -20       0      0      0 S   0.0  0.0   0:00.00 kworker/0:0H                                                                                                          </span><br><span class="line">      7 root      rt   0       0      0      0 S   0.0  0.0   0:53.07 migration/0                                                                                                           </span><br><span class="line">      8 root      20   0       0      0      0 S   0.0  0.0   0:00.00 rcu_bh                                                                                                                </span><br><span class="line">      9 root      20   0       0      0      0 S   0.0  0.0   0:00.00 rcuob/0                                                                                                               </span><br><span class="line">     10 root      20   0       0      0      0 S   0.0  0.0   0:00.00 rcuob/1                                                                                                               </span><br><span class="line">     11 root      20   0       0      0      0 S   0.0  0.0   0:00.00 rcuob/2                                                                                                               </span><br><span class="line">     12 root      20   0       0      0      0 S   0.0  0.0   0:00.00 rcuob/3                                                                                                               </span><br><span class="line">     13 root      20   0       0      0      0 S   0.0  0.0   0:00.00 rcuob/4                                                                                                               </span><br><span class="line">     14 root      20   0       0      0      0 S   0.0  0.0   0:00.00 rcuob/5                                                                                                               </span><br><span class="line">     15 root      20   0       0      0      0 S   0.0  0.0   0:00.00 rcuob/6                                                                                                               </span><br><span class="line">     16 root      20   0       0      0      0 S   0.0  0.0   0:00.00 rcuob/7                                                                                                       </span><br><span class="line">     17 root      20   0       0      0      0 S   0.0  0.0   0:00.00 rcuob/8                                                                                                               </span><br><span class="line">     18 root      20   0       0      0      0 S   0.0  0.0   0:00.00 rcuob/9                                                                                                               </span><br><span class="line">     19 root      20   0       0      0      0 S   0.0  0.0   0:00.00 rcuob/10                                                                                                              </span><br><span class="line">     20 root      20   0       0      0      0 S   0.0  0.0   0:00.00 rcuob/11                                                                                                              </span><br><span class="line">     21 root      20   0       0      0      0 S   0.0  0.0  94:17.16 rcu_sched</span><br></pre></td></tr></table></figure>
<p>通过此命令可一目了然得看出系统资源的负载是否较高，哪些进程占用了较多资源等，以便进一步分析</p>
<h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul>
<li><a href="https://medium.com/netflix-techblog/linux-performance-analysis-in-60-000-milliseconds-accc10403c55" target="_blank" rel="noopener">Linux Performance Analysis in 60,000 Milliseconds</a></li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/11/09/rgw-multi-site/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Leeshine">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Leesine's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/11/09/rgw-multi-site/" itemprop="url">rgw-multisite概述</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-11-09T21:17:40+08:00">
                2018-11-09
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>rgw-multisite主要涉及涉及到三种日志：</p>
<ul>
<li>metadata log</li>
<li>data log</li>
<li>bucket index log</li>
</ul>
<h3 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h3><ul>
<li>zone：每个zone都是独立的ceph集群，包含osd、mon、rgw等，不会跨集群，A <em>zone</em> in the RGW multisite system is a set of radosgw daemons serving the same data, backed by the same set of RADOS pools in Ceph（由一组rgw提供服务，对应一组后台的pool）</li>
<li>zonegroup：可以包含多个zone，zone之间同步元数据和数据，其中只有master zone能修改元数据</li>
<li>realm：独立命名空间，可以包含zonegroup，zonegroup之间同步元数据，只有master zonegroup能修改元数据，用以支持在同一组集群中运行不同配置</li>
<li>period：拥有唯一id和epoch，用以保持当前realm的状态，每个realm都有当前关联的period以及一组按照时间顺序排列的period</li>
<li>user：user在realm里是全局唯一的</li>
<li>bucket：在realm里是全局唯一的，且只属于一个zonegroup</li>
<li>A sync module is a set of callbacks that are called for each change that happens in data (and potentially in metadata, e.g., bucket creation, new user, etc.; note: object’s metadata change is regaded as change in data) in a single zone-group. sync module是针对底层数据变化实现的一系列回调，每个zone都有一个对应的sync module，这个sync module决定了这个对应的zone能否导出数据</li>
</ul>
<h3 id="日志格式"><a href="#日志格式" class="headerlink" title="日志格式"></a>日志格式</h3><h1 id="核心机制"><a href="#核心机制" class="headerlink" title="核心机制"></a>核心机制</h1><h3 id="集群配置同步（realm-sync）"><a href="#集群配置同步（realm-sync）" class="headerlink" title="集群配置同步（realm sync）"></a>集群配置同步（realm sync）</h3><ul>
<li>变更极致类似于git，需要update后再提交才能被其他节点感知，首次使用时需要通过pull命令来获取更新，之后的推送是主动的（RGWPeriodPusher实现了RGWRealmWatcher接口）</li>
<li>RGWPeriodPusher：与其他节点一起通过realm watcher 来推送period的更新</li>
</ul>
<h3 id="元数据同步-（meta-sync）"><a href="#元数据同步-（meta-sync）" class="headerlink" title="元数据同步 （meta sync）"></a>元数据同步 （meta sync）</h3><ul>
<li>元数据同步和数据同步分为全局同步和增量同步，元数据的修改只能发生在master zone上，更新的过程就是通过radosgw admin api来获取metadata log，并更新对应marker</li>
</ul>
<h3 id="数据同步（data-sync）"><a href="#数据同步（data-sync）" class="headerlink" title="数据同步（data sync）"></a>数据同步（data sync）</h3><ul>
<li>更新的过程就是通过RGW Admin API来获取bilog，并更新对应的marker，从日志处获取信息差异后请求对方zone已变化数据的元数据信息，并调用底层module的相关接口</li>
<li>zone_data sync status ：init 、 full_sync 、 incremental<ul>
<li>bucket_instance_state: full_sync 、 incremental</li>
</ul>
</li>
<li>执行流程（RGWDataSyncCR）：<ul>
<li>RGWReadDataSyncStatusCoroutine：获取对应zone的同步状态<ul>
<li>从log-pool中获取datalog.sync-status.{source-zone-id}，该obejct存储了同步状态(<strong>State</strong>)以及日志分片数（state、num_shards）</li>
<li>处理每个日志分片，从log-pool中获取datalog.sync-status.shard.{source-zone-id}.X，该object存储了同步阶段，以及同步的marker</li>
</ul>
</li>
<li>若<strong>State</strong> 为<strong>StateInit</strong>，RGWInitDataSyncStatusCoroutine<ul>
<li>锁住datalog.sync-status.{source-zone-id}，并创建一个新的object，创建完成之后再锁住</li>
<li>处理每个日志分片，读取remote pool（rgw.log），remote-obj（data_logX）并保存shards_info[X]</li>
<li>对上步获取到的信息shards_info，存入本地集群中local pool(rgw.log)，local obj（datalog.sync-status.shard.{source-zone-id}.X）</li>
<li>将状态改变为<strong>StateBuildingFullSyncMaps</strong>（修改前文锁住的object并解锁）</li>
</ul>
</li>
<li>若<strong>State</strong> 为<strong>StateBuildingFullSyncMaps</strong>，RGWListBucketIndexesCR<ul>
<li>创建entries_index（RGWShardedOmapCRManager），local pool(rgw.log), objects( data.full-sync.index.{source-zone-id}.0，。。)obj数等于bucket分片数</li>
<li>从remote zone处获取bucket instances（RGWReadRESTResourceCR）</li>
<li>对于上步获取的每个bucket instance，获取详细信息（RGWReadRESTResourceCR ），详细信息包括：num_shards、name of bucket、index pool、data pool。。，对于每个bucket分片<ul>
<li>将key（ {bucket-name-A}:{source-zone-id}.4133.1），value（empty）写入前文entries_index obj 处</li>
</ul>
</li>
<li>对于每个日志分片X，有[bucket，shard]对应与X，该对应关系被写入日志中</li>
</ul>
</li>
<li>若<strong>State</strong> 为<strong>StateSync</strong>，对每个日志分片X分别处理（ RGWDataSyncShardControlCR-》RGWDataSyncShardCR）<ul>
<li>​</li>
</ul>
</li>
</ul>
</li>
</ul>
<h1 id="插件机制"><a href="#插件机制" class="headerlink" title="插件机制"></a>插件机制</h1><h3 id="sync-plugin"><a href="#sync-plugin" class="headerlink" title="sync plugin"></a>sync plugin</h3><ul>
<li>data sync module：获取数据并写入本地，支持数据导出</li>
<li>log sync module：获取数据的扩展属性，不支持数据导出</li>
<li>elasticsearch module：获取同步数据的元数据信息</li>
</ul>
<h1 id="公有云同步"><a href="#公有云同步" class="headerlink" title="公有云同步"></a>公有云同步</h1><h2 id="数据同步机制-data-sync"><a href="#数据同步机制-data-sync" class="headerlink" title="数据同步机制(data sync)"></a>数据同步机制(data sync)</h2><h2 id="Multi-site-同步示例"><a href="#Multi-site-同步示例" class="headerlink" title="Multi-site 同步示例"></a>Multi-site 同步示例</h2><p>本文环境中分为source site 和 secondarysite两个集群，在source site上修改bucket中的数据，在secondary site上观察数据同步状态</p>
<h3 id="数据机制浅析"><a href="#数据机制浅析" class="headerlink" title="数据机制浅析"></a>数据机制浅析</h3><p>/<strong><strong><strong><strong>**</strong></strong></strong></strong> remote site <strong>***</strong>/</p>
<p>涉及到的存储池：</p>
<ul>
<li><strong>{source-zone}.rgw.data.root</strong>：存储bucket instances</li>
<li><strong>{source-zone}.rgw.buckets.data</strong>：存储Objects</li>
<li><strong>{source-zone}.rgw.buckets.index</strong>：存储bucket对应的index objcet（与bucket index 的分片数有关）</li>
<li><strong>{source-zone}.rgw.log</strong>：存储修改日志（与日志分片数有关）</li>
</ul>
<p>注意：总共有两种分片，分别为bucket shard ， log shard</p>
<p>将bucket 分片与日志分片做映射，假设测试环境中有3个bucket（bucket-0,bucket-1,bucket-2），bucket的分片数为3（rgw_override_bucket_index_max_shards=3），日志分片数为4（rgw_data_log_num_shards=4），那么需要将9个bucket shard 与4个log shard 做映射，之后针对每个bucket  shard 的修改都会记录到对应的log shard 之上，下面以objcet的写入为例来分析数据同步流程：</p>
<p>假设将OBJ_test 写入bucket-0 shardS中，该bucket shard 对应与 log shardX，则流程如下:</p>
<p>1) 将OBJ_test写入pool（{source-zone}.rgw.buckets.data）中</p>
<p>2) 将修改信息写入pool（{source-zone}.rgw.buckets.index）的obj（.dir.{key-of-bucket-0}.S）的omap属性中：</p>
<p>​    &lt;OBJ_test， 基本元信息&gt;，&lt;.0_00000000001.4.2，_ write OBJ_444 state=CLS_RGW_STATE_PENDING_MODIFY_&gt;，&lt;.0_00000000002.5.3，write OBJ_444 state=CLS_RGW_STATE_COMPLETE&gt;</p>
<p>之后在omap的header中记录值 0_00000000002.5.3</p>
<p>3) 将修改信息写入pool （{source-zone}.rgw.log）的obj（data_log.X）的omap属性中：</p>
<p>1_1489979397.374156_23.1 =》some info like bucket-B shardS has modification, timestamp</p>
<p>之后再omap的header中记录值1_1489979397.374156_23.1</p>
<p>总结来说，当在某个bucket做了数据修改时，所做的修改都会以kv的形式记录在对应的obj的omap中，其中k为系统生成的有序的marker，v为对应的一些元数据信息，同时在omap的header中会记录最近的一个marker</p>
<h3 id="实例"><a href="#实例" class="headerlink" title="实例"></a>实例</h3><h3 id="代码分析"><a href="#代码分析" class="headerlink" title="代码分析"></a>代码分析</h3><p>本文接上文，对multi-site中数据同步的部分代码做分析，环境还是分为source-zone和 secondary-zone两个zone分别对应两个seal集群，实验过程中在source-zone上写入object，在secondary-zone上观察数据同步状态 。</p>
<p>RGWDataSyncCR为实际执行数据同步的入口协程，因为本文主要以该类为起点来分析multi-site中数据增量同步（inc_sync）的过程。multi-site的实现中在boost::asio::coroutine的基础之上封装了一个协程库，在该库之上使用了大量协程来完成数据的同步。下面以secondary-zone为视角来分析数据同步过程。</p>
<p>RGWDataSyncCR:</p>
<ol>
<li><p>RGWReadDataSyncStatusCoroutine：</p>
<p>从本地集群中获取远端集群数据同步状态（“state”）和日志分片数（“num_shards”），并存入到sync_status.sync_info中，对于远端集群的每个日志分片data-log-shard X，从本地集群中读取该分片同步状态(full-sync inc-sync)、marker、next_step_marker、timestamp这些信息，并存入sync_status-&gt;sync_markers[X]中:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">local-pool: &#123;secondary-zone&#125;.rgw.log</span><br><span class="line">local-obj: datalog.sync-status.&#123;remote-zone-id&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>如果1中获取的”state”为”StateInit“，RGWInitDataSyncStatusCoroutine：</p>
<p>  2.1 锁住 datalog.sync-status.{remote-zone-id} 这个object</p>
<p>  2.2 重新创建这个object（ datalog.sync-status.{remote-zone-id}）</p>
<p>  2.3 再次锁住这个object</p>
<p>  2.4 对于每个日志分片data-log-shard X，从远程集群中</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">remote-pool: &#123;source-zone&#125;.rgw.log</span><br><span class="line">remote-obj: data-log.X</span><br></pre></td></tr></table></figure>
<p>获取该日志分片的信息，写入shards_info[x]，之后将shards_info[x]写入本地集群中</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">local-pool : &#123;secondary-zone&#125;.rgw.log </span><br><span class="line">local-obj :  datalog.sync-status.shard.&#123;source-zone-id&#125;.X</span><br></pre></td></tr></table></figure>
<p>经过这步之后，日志分片的映射情况如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">source-zone                   secondary-zone</span><br><span class="line">data_log.0     ======&gt;    datalog.sync-status.shard.&#123;source-zone-id&#125;.0</span><br><span class="line">......</span><br><span class="line">   data_log.X     ======&gt;    datalog.sync-status.shard.&#123;source-zone-id&#125;.X</span><br></pre></td></tr></table></figure>
<ol start="2">
<li>5 将数据同步状态设置为”StateBuildingFullSyncMaps”，同时写入本地集群 datalog.sync-status.{remote-zone-id} 这个object中，并将该object解锁</li>
</ol>
</li>
<li><p>如果1.1中获取的”state”为“StateBuildingFullSyncMaps”，RGWListBucketIndexesCR：</p>
<p>注：如果是在source-zone和secondary-zone都为空的时候配置multi-site，步骤3不做任何事，因为在build full sync map的时候没有任何数据</p>
<p>  3.1 创建entries_index（ RGWShardedOmapCRManage），用于管理建立full sync map过程中本地的一些obj</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">local-pool: &#123;secondary-zone&#125;.rgw.log</span><br><span class="line">local-obj: data.full-sync.index.&#123;remote-zone-id&#125;.0</span><br><span class="line">			data.full-sync.index.&#123;remote-zone-id&#125;.1</span><br><span class="line">			...</span><br><span class="line">			data.full-sync.index.&#123;remote-zone-id&#125;.N, N = rgw_data_log_num_shards</span><br></pre></td></tr></table></figure>
<p>由上可知，每个本地的data.full-sync.index object对应于远端集群的一个data_log，下面则需要同步远端bucket的信息，并将bucket分片与本地的data.full-sync.index object建立对应关系</p>
<p>  3.2 调用RGWReadRESTResourceCR从source zone处获取所有bucket instance</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">remote-pool : &#123;source-zone&#125;.rgw.data.root</span><br><span class="line">remote-obj: .bucket.meta.&#123;bucket-name-A&#125;:&#123;remote-zone-id&#125;.4133.1</span><br><span class="line">			.bucket.meta.&#123;bucket-name-B&#125;:&#123;remote-zone-id&#125;.4139.2</span><br><span class="line">			.bucket.meta.&#123;bucket-name-C&#125;:&#123;remote-zone-id&#125;.4138.3</span><br><span class="line">			....</span><br></pre></td></tr></table></figure>
<p> 3.3 对于3.2步中获取的每个bucket instance（例如 {bucket-name-A}:{remote-zone-id}.4133.1）调用RGWReadRESTResourceCR 获取该bucket的详细信息，包括：bucket分片数（即该bucket的index分片数）、bucket的名字、index pool、data pool等，对于每个bucket分片，做如下处理（以分片i为例）：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"># 假设分片i映射到了日志分片data_log.X上</span><br><span class="line">set omap (key:&#123;bucket-name-A&#125;:&#123;source-zone_id&#125;.4133.1 val:empty)</span><br><span class="line">to local obj(local-pool: &#123;secondary-zone&#125;.rgw.log, local-obj:data.full-sync.index.&#123;remote-zone-id&#125;.X)</span><br></pre></td></tr></table></figure>
<p>最后，data.full-sync.index.{remote-zone-id}.X上记录了对应的remote-zone上的bucket 分片，例如：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"># rados -p &#123;zone&#125;.rgw.log listomapkeys data.full-sync.index.&#123;remote-zone-id&#125;.3</span><br><span class="line"> testbuckAAA:900d449b-3c56-4949-8b88-bc8a6d4ee3b1.4122.1:1</span><br><span class="line"> testbuckAAA:900d449b-3c56-4949-8b88-bc8a6d4ee3b1.4122.1:5</span><br><span class="line"> testbuckBBB:900d449b-3c56-4949-8b88-bc8a6d4ee3b1.4123.2:1</span><br><span class="line"> testbuckBBB:900d449b-3c56-4949-8b88-bc8a6d4ee3b1.4123.2:5</span><br><span class="line"> testbuckCCC:900d449b-3c56-4949-8b88-bc8a6d4ee3b1.4124.3:1</span><br><span class="line"> testbuckCCC:900d449b-3c56-4949-8b88-bc8a6d4ee3b1.4124.3:5</span><br><span class="line"> 这就是说：</span><br><span class="line">  testbuckAAA, shard1</span><br><span class="line">  testbuckAAA, shard5</span><br><span class="line">  testbuckBBB, shard1</span><br><span class="line">  testbuckBBB, shard5</span><br><span class="line">  testbuckCCC, shard1</span><br><span class="line">  testbuckCCC, shard5</span><br><span class="line">  这几个bucket分片被映射到data_log.X这个分片上</span><br></pre></td></tr></table></figure>
<p> 3.4 对于每个日志分片data_log.X，记录被映射到这个日志分片上的bucket 分片数量：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">local-pool :  &#123;secondary-zone&#125;.rgw.log</span><br><span class="line">local-obj : datalog.sync-status.shard.&#123;remote-zone-id&#125;.X</span><br></pre></td></tr></table></figure>
<p>​</p>
</li>
<li><p>如果1中获取的”state”为“StateSync”，对于每个日志分片 data-log-shard X，调用RGWDataSyncShardCR::incremental_sync来进行增量同步：</p>
<p>   4.2 创建set_marker_tracker（RGWDataSyncShardMarkerTrack），用来记录一个bucket shard是否在流程中和更新一个marker</p>
<ol start="5">
<li><p>5 读取远端集群中data-log.X这个object的omap header，header中包含的信息由max_marker，max_time， 如果读取的max_marker比本地记录的marker更旧的话，那么此次增量同步结束</p>
<p>4.6 如果读取的max_marker比本地记录的marker更新的话，从远端集群中的data-log.X中读取这个object的omap kv对（每个kv对为一个entry），从RGWDataChangesLog::add_entry方法中可以看出这些kv对是如何组成的：</p>
</li>
</ol>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">1_1489653363.684562_381.1 =&gt; some info including bucke-tname, bucked-id, bucket-shard, modification timestamp</span><br><span class="line">1_1489653363.684562_381.1这个key是在 cls/log/cls_log.cc:cls_log_add中根据时间戳生成的</span><br></pre></td></tr></table></figure>
<p>对于一个bucket的任何修改都会生成一个这样的kv对存储在对应的日志分片上，因此扫描一个日志分片data_log.X的话，结果如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"># rados -p &#123;source-zone&#125;.rgw.log listomapkeys data_log.X</span><br><span class="line"> 1_1490768507.881727_3.1 =&gt; some info like bucket-2 shard3 has modification timestamp1</span><br><span class="line"> 1_1490768519.257779_4.1 =&gt; some info like bucket-5 shard1 has modification timestamp2</span><br><span class="line"> 1_1490768527.759371_5.1 =&gt; some info like bucket-1 shard4 has modification timestamp3</span><br><span class="line"> 1_1490768541.378290_6.1 =&gt; some info like bucket-6 shard0 has modification timestamp4</span><br><span class="line"> ......</span><br></pre></td></tr></table></figure>
<p>  4.7 对于4.6中返回的每个entry，如果它还没有在处理流程中（由4.2中创建的marker_tracker判断），则通过协程RGWDataSyncSingleEntryCR来处理每个entry：</p>
<ul>
<li>解析该entry从而获取bucket_name和bucket_shard_id</li>
</ul>
<ul>
<li><p>调用协程RGWRunBucketSyncCoroutine来处理该bucket shard的数据同步：</p>
<ul>
<li><p>a) 调用协程RGWReadBucketSyncStatusCoroutine从本地集群中读取对应object的xattrs（包含的信息有：full_marker、inc_marker、lock.sync_lock、lock.sync_lock.incremental、state等）</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">local-pool : &#123;secondary-zone&#125;.rgw.log</span><br><span class="line">local-obj : bucket.sync-status.&#123;remote-zone-id&#125;:&#123;bucketname&#125;:&#123;bucket_id&#125;:&#123;shard_id&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>b) 调用协程RGWGetBucketInstanceInfoCR从本地集群中读取bucket instance的信息</p>
</li>
<li><p>c) 如果步骤a中获取的state为rgw_bucket_shard_sync_info::StateInit（与步骤1中获取的状态不同，步骤一种状态为rgw_data_sync_info::StatInit），调用协程 RGWInitBucketShardSyncStatusCoroutine从远端集群中读取对应的bucket index log 的相关信息写入本地集群中，同时将状态置为”StateFullSync”</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">remote-pool : &#123;source-zone&#125;.rgw.buckets.index</span><br><span class="line">remote-obj : .dir.&#123;key-of-bucket-B&#125;.S</span><br><span class="line"></span><br><span class="line">local-pool : &#123;secondary-zone&#125;.rgw.log</span><br><span class="line">local-obj : bucket.sync-status.&#123;remote-zone-id&#125;:&#123;bucketname&#125;:&#123;bucket_id&#125;:&#123;shard_id&#125;</span><br></pre></td></tr></table></figure>
</li>
<li><p>d) 如果步骤a中获取的state为StateFullSync，调用协程RGWBucketShardFullSyncCR将状态置为“ StateIncrementalSync”</p>
</li>
<li><p>e)如果步骤a中获取的状态为StateIncrementalSync，调用RGWBucketShardIncrementalSyncCR：</p>
<ul>
<li><p>调用RGWListBucketIndexLogCR从远端集群中获取bucket分片的相关信息（omap kv对)：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">remote-pool: &#123;source_zone&#125;.rgw.buckets.index</span><br><span class="line">remote-obj : .dir.&#123;key-of-bucket-B&#125;.S</span><br></pre></td></tr></table></figure>
<p>对于每个kv对，调用RGWBucketSyncSingleEntryCR来对对应的object进行同步：</p>
<ul>
<li><p>若这个kv对应的操作没有完成（op_state != CLS_RGW_STATE_COMPLETE），则跳过</p>
</li>
<li><p>若对应的操作已完成（op_state == CLS_RGW_STATE_COMPLETE），则根据具体的操作类型调用RGWDefaultDataSyncModule中的具体方法来实现对该object的操作，具体的方法包括：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">sync_object: 将远端object同步到本地集群中</span><br><span class="line">remove_object: 将objcet从本地集群中删除</span><br><span class="line">create_delete_marker: 对于开启了version功能的bucket，给对应的object创建一个删除标记，而不是直接删除该object</span><br></pre></td></tr></table></figure>
<p>​</p>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
</ol>
<p>rgw_admin.cc::get_data_sync_status分析</p>
<ul>
<li>RGWDataSyncStatusManager::init():<ul>
<li>source_log.init ： 初始化source zone的data_log</li>
<li>source_log.read_log_info：获取source zone的data_log数目</li>
</ul>
</li>
<li>RGWRemoteDataLog::read_sync_status()，将读取结果存储到sync_status中<ul>
<li>RGWReadDataSyncStatusCoroutine<ul>
<li>RGWSimpleRadosReadCR&lt;rgw_data_sync_info&gt;：获取sync info</li>
<li>RGWReadDataSyncStatusMarkersCR：获取日志分片的marker</li>
</ul>
</li>
</ul>
</li>
<li>从sync_status中读取同步状态（init、preparing for full sync 、syncing），计算full sync、inc sync的分片数目</li>
<li>RGWRemoteDataLog::read_source_log_shards_info()：统计尚未同步的分片数，获取最近的已同步的修改点</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/11/09/paxos-introduction/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Leeshine">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Leesine's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/11/09/paxos-introduction/" itemprop="url">PAXOS简介</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-11-09T21:02:11+08:00">
                2018-11-09
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="推导过程"><a href="#推导过程" class="headerlink" title="推导过程"></a>推导过程</h2><p>对于一致性算法来说，安全性要求如下：</p>
<ul>
<li>只有被提出的方案才能被选定（chosen）</li>
<li>只有一个值能被选定</li>
<li>进程不会学习某个方案，除非这个方案真正被选定了</li>
</ul>
<p>Paxos就是一个满足上述需求的一致性算法，它的目标是确保最终有一个方案能被选定，然后被所有进程学习，Paxos中有三种角色：<code>proposers</code> , <code>acceptors</code>, <code>learners</code>，所有的角色都能互通信，并由如下前提：</p>
<ul>
<li>agent以不固定速度运行，可能会停止或者重启。因为即使一个提案被选定了，agent也可能重启，因此被选定的提案能持久化存储，否则无法确定最终的值</li>
<li>消息在传输过程中可能会丢失、重复，等内容不会被篡改</li>
</ul>
<p>首先，即使只有一个提案被提出，我们仍要确保最终有一个方案会被选定，这就暗示这如下需求：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">P1: 一个Acceptor必须批准它接收到的第一个提案</span><br></pre></td></tr></table></figure>
<p>但是这个需求会引出新的问题：如果有多个提案被多个Proposer同时提出，会导致每个Acceptor都批准了一个提案，但没有哪个提案被多数派批准。因此在P1基础上，为了确保最终有提案能被多数派批准，这就意味着一个Acceptor必须能批准不止一个提案，我们使用一个全局唯一的编号来唯一标识每一个被Acceptor批准的提案，此时可以用<code>[编号，value]</code>来表示一个提案，当一个提案被多数派批准之后，我们就说这个提案被选定了（chosen）。我们可以允许多个提案被选定，但是我们必须确保被选定的提案都具有相同的值，即有如下需求：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">P2: 如果一个值为V的提案被选定了，那么被选定(chosen)的更高编号的提案的值也必须为V</span><br></pre></td></tr></table></figure>
<p>因为编号是全局有序递增的，这样才能确保最终只有一个值能被选定。一个提案被选定意味它至少被一个Acceptor批准，因此我们可以满足如下条件来满足P2：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">P2a: 如果一个值为V的提案被选定了，那么被批准(accept)的更高编号的提案的值也必须为V</span><br></pre></td></tr></table></figure>
<p>此时，我们仍需满足P1，但因为通信是异步的，一个提案（[M0, V0]）可能会在某个Acceptor还未收到任何提案时就被选定了，如果此时某个Proposer产生了一个编号更高，值不为V0提案（[M1, V1], M1&gt;M0, V1 != V0）发送至该Acceptor，那么该提案就会被批准，但这会与P2a相矛盾，因此对P2a进行强化如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">P2b: 如果一个值为V的提案被选定了，那么之后任何Proposer产生的编号更高的提案，其值都必须为V</span><br></pre></td></tr></table></figure>
<p>因此我们满足P2b即可满足P2。接下来我们来讨论如何满足P2b，即如何满足<code>在[M0, V0]被选定时,所有编号Mn &gt; M0的提案，其值也为V0</code>。只需要满足如下约束即可：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">P2c: 如果提案[Mn, Vn]被提出，那么肯定存在一个由半数以上Acceptor组成的集合S，满足如下两个条件之一：</span><br><span class="line">- S中的所有Acceptor都没有批准过编号小于Mn的提案</span><br><span class="line">- S中所有Acceptor批准的最大编号的提案的值为Vn</span><br></pre></td></tr></table></figure>
<p>下面我们来证明P2c成立的话，P2b也一定成立。我们可以使用第二数学归纳法来证明，即首先假设提案[M0, V0]被选定了，证明过程如下：</p>
<ol>
<li>当Mn = M0 + 1时，因为M0已经被选定了，那么肯定不存在一个多数派集合S，其中所有Acceptor都没有批准过编号小于Mn的提案，即P2c中第一个条件肯定不成立了，所以肯定存在多数派Acceptor集合S1，其批准的最大编号的提案只为Vn，因为M0被选定了，所有肯定存在多数派Acceptor集合C，C中每个Acceptor都批准了M0这个提案，因为C与S1必然有交集，所以S1中最大编号的提案一定为M0，所以此时Vn必然等于V0</li>
<li>根据第二数学归纳法，假设编号M0+1 值Mn-1 范围内的所有提案值都为V0，那么如何证明Mn提案的值也为V0呢？根据P2c，肯定存在一个多数派集合S，S中的Acceptor批准了编号小于Mn的提案，且它批准的最大编号的提案的值肯定为Vn，假设这个最大编号落在[M0+1, Mn-1]区间内，则Vn肯定等于V0，若不在这个区间内，那最大编号肯定为M0，此时Vn也肯定等于V0</li>
</ol>
<p>由此可证明，在P2c的约束条件下，P2b是成立的。从上可看到，从P1到P2c的过程其实是一系列条件的加强，由P2c进行反向推导就可保证P2的成立。将条件逐步加强后，就可以推导出提案的生成步骤了，下面我们来看应该如何满足P2c。</p>
<h2 id="提案流程"><a href="#提案流程" class="headerlink" title="提案流程"></a>提案流程</h2><h3 id="Proposer生成提案"><a href="#Proposer生成提案" class="headerlink" title="Proposer生成提案"></a>Proposer生成提案</h3><p>下面来看在P2c的基础上如何来生成提案。对于Proposer来说，学习已经被批准或即将批准的提案肯定比预测未来被批准的提案更容易，因此，Proposer在生成提案N时，它需要学习这样一个提案M，M被多数派Acceptor批准且M为小于N中提案中编号最大的提案（如果这个提案存在的话）。既然预测未来提案较难，Proposer可以采取一些方法来反正其他提案（值不相同）被批准，Paxos中采用的方法就是Proposer会要求Acceptor不再批准编号小于N的提案，这就引出了如下提案生成算法：</p>
<p>1.<strong>Prepare阶段</strong><br>Proposer获取一个提案编号N，然后向某个多数派Acceptor集合发出请求，要求集合中的Acceptor做出如下回应：</p>
<ul>
<li>不再批准任何编号小于N的提案</li>
<li>反馈已批准的编号小于N中编号最大的提案（如果有的话）</li>
</ul>
<p>2.<strong>Accept阶段</strong><br>Proposer在接收到半数以上Acceptor的回复之后，生成编号为N的提案[N, V]，V就是在Prepare阶段中所有响应中编号最大的提案的值，如果这些Acceptor都没有批准过任何值的话，V的值就由Proposer决定</p>
<p>在确定提案后，Proposer就会将提案再次发送个半数以上的Acceptor集合，此为Accept请求。需要注意的是，此时的多数派集合跟Prepare阶段的多数派集合并不是一定相等的。</p>
<h3 id="Acceptor批准提案"><a href="#Acceptor批准提案" class="headerlink" title="Acceptor批准提案"></a>Acceptor批准提案</h3><p>下面来看Acceptor的处理逻辑，Acceptor会接收到两种请求：prepare及accept，它的处理分别如下：</p>
<ul>
<li>Prepare请求：可以在任何时间响应</li>
<li>Accept请求：在不违背承诺的前提下课任意响应，</li>
</ul>
<p>即Acceptor批准提案的约束条件如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">P1a: 只有在没有响应过任何编号大于N的prepare请求时，它才能批准这个编号为N的提案</span><br></pre></td></tr></table></figure>
<h3 id="算法整体流程"><a href="#算法整体流程" class="headerlink" title="算法整体流程"></a>算法整体流程</h3><p>结合前文内容，可以得到如下类似两阶段提交的Paxos算法执行流程：</p>
<h4 id="阶段一"><a href="#阶段一" class="headerlink" title="阶段一"></a>阶段一</h4><ol>
<li>Proposer获取一个提案编号N，然后向一个多数派Acceptor集合发送Prepare请求</li>
<li>如果一个Acceptor接收到一个编号为N的Prepare请求，且N大于它已经响应的所有Prepare请求的编号，它会将自己批准过的编号最大的提案值反馈给Proposer，同时该Acceptor不会再批准任何编号小于N的提案</li>
</ol>
<h4 id="阶段二"><a href="#阶段二" class="headerlink" title="阶段二"></a>阶段二</h4><ol>
<li>如果Proposer收到半数以上Acceptor的Prepare响应，它就会发送提案为[N, V]的Accept请求至一个多数派Acceptor集合，其中V为响应的prepare请求中编号最大的提案值，如果这个值不存在则V会有该Proposer自行生成</li>
<li>一个Acceptor接收到[N, V]这个提案后，只要它没有响应过编号大于N的Prepare请求，它就可以批准这个提案 </li>
</ol>
<p>在实际使运行过程中，一个proposer可能会产生多个提案，但只要遵循上述流程，就一定能得到最终的正确结果，且一个proposer可以在任意时刻丢弃一个提案。</p>
<h2 id="实际使用"><a href="#实际使用" class="headerlink" title="实际使用"></a>实际使用</h2><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">TO DO</span><br></pre></td></tr></table></figure>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/11/09/crush/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Leeshine">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Leesine's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/11/09/crush/" itemprop="url">CRUSH算法</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-11-09T20:51:25+08:00">
                2018-11-09
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>在大型分布式存储系统中，如果使用哈希分布的方式来将数据打散的话有两个问题需要考虑：</p>
<ul>
<li>如果系统中有设备发生变化，如何在迁移最少数据量的情况下保持系统平衡</li>
<li>数据的多个副本之间要如何分布才能使数据有较高的可靠性</li>
</ul>
<p>显而易见，普通哈希函数是较难解决以上两个问题的，而CRUSH（Controlled Replication Under Scalable Hashing）就是一个在普通哈希之上进行扩展用以解决以上两个问题的数据分布算法。</p>
<p>CRUSH具有如下特点：</p>
<ul>
<li>以数据唯一标识、当前存储集群拓扑结构、数据备份策略作为输入，返回一组存储设备用以保存数据副本</li>
<li>只需保存很少元数据（cluster map），只有当设备发生变化时，才会修改这些元数据</li>
<li>用公式描述就是CRUSH(X) –&gt; (OSD1, OSD2, OSD…)，其中输入参数包括X（pgid），cluster map，placement rule</li>
</ul>
<h2 id="Cluster-Map"><a href="#Cluster-Map" class="headerlink" title="Cluster Map"></a>Cluster Map</h2><p>cluster map描述了ceph集群中有层级关系的静态拓扑结构，这样使得CRUSH在选择OSD时有机架感知能力，配合预先定义的placement rule（分布规则），就可以使副本分布在不同机架、机房中，提高数据的可用性。cluster map中包含如下概念：</p>
<ul>
<li>Device：OSD，一个OSD对应一个存储设备</li>
<li>Bucket：设备容器，可以递归包含多个设备或者子类型bucket。目前有root、region、datacenter、room、rack、host等，每个device都有自己的权重，bucket的权重就是子bucket和device的权重之和</li>
</ul>
<h2 id="Placement-rule"><a href="#Placement-rule" class="headerlink" title="Placement rule"></a>Placement rule</h2><p>通过cluster map来建立集群对应的拓扑结构后，就可以通过placement rule来描述数据分布规则。每条placement rule包含多个操作，这些操作总总共有3种类型：</p>
<ul>
<li>take：选择每个bucket，以此为后续步骤的输入</li>
<li>choose：从输入的bucket中选择指定类型和数量的items</li>
<li>emit：返回最终结果</li>
</ul>
<p>一个典型的placement rule有如下定义格式：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">take a</span><br><span class="line">choose </span><br><span class="line">	choose firstn &#123;num&#125; type &#123;bucket-type&#125;</span><br><span class="line">	chooseleaf firstn &#123;num&#125; type &#123;bucket-type&#125;</span><br><span class="line">		if &#123;num&#125; == 0, choose &#123;pool-num-replicas&#125; buckets </span><br><span class="line">		if &#123;num&#125; &gt; 0 &amp;&amp; &lt; &#123;pool-num-replicas&#125;, choose &#123;num&#125; buckets</span><br><span class="line">		if &#123;num&#125; &lt; 0, choose &#123;pool-num-replicas&#125; - |&#123;num&#125;| buckets</span><br><span class="line">emit</span><br></pre></td></tr></table></figure>
<p>对应的流程如下：</p>
<p>1） take a ：选择a这个bucket，一般为root类型的bucket</p>
<p>2）choose操作有不通的选择方式，其输入都是上一步的输出：</p>
<ul>
<li>choose firstn 选出num 个类型为bucket-type类型的bucket</li>
<li>chooseleaf  先选出num个类型为bucket-type类型的bucket，然后递归到叶节点，选出一个OSD设备：<ul>
<li>如果num为0，则num被设置为pool的副本数</li>
<li>如果num大于0且小于pool的副本数，则选择num个</li>
<li>如果num小于0，则选择pool的副本数减去|num|个</li>
</ul>
</li>
</ul>
<p>3） emit：输出结果</p>
<p>其中chooseleaf firstn {num} {bucket_-type}可以等价为以下两个操作：</p>
<p>​    a）choose firstn {num} {bucket-type}</p>
<p>​    b） choose first 1 osd</p>
<p>如下为一个集群中使用的placement rule实例，采用将3副本分布在不同主机上的容灾模式：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line">root default &#123;</span><br><span class="line">        id -1           # do not change unnecessarily</span><br><span class="line">        id -2 class hdd         # do not change unnecessarily</span><br><span class="line">        # weight 305.650</span><br><span class="line">        alg straw2</span><br><span class="line">        hash 0  # rjenkins1</span><br><span class="line">        item default-100.98.49.161 weight 43.664</span><br><span class="line">        item default-100.98.46.210 weight 43.664</span><br><span class="line">        item default-100.98.49.174 weight 43.664</span><br><span class="line">        item default-100.98.49.234 weight 43.664</span><br><span class="line">        item default-100.98.49.229 weight 43.664</span><br><span class="line">        item default-100.98.49.251 weight 43.664</span><br><span class="line">        item default-100.98.49.224 weight 43.664</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">rule cos_rep_default_host &#123;</span><br><span class="line">        id 7</span><br><span class="line">        type replicated</span><br><span class="line">        min_size 1</span><br><span class="line">        max_size 10</span><br><span class="line">        step take default</span><br><span class="line">        step chooseleaf firstn 0 type host</span><br><span class="line">        step emit</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="Bucket-选择算法"><a href="#Bucket-选择算法" class="headerlink" title="Bucket 选择算法"></a>Bucket 选择算法</h2><p>前文描述了CRUSH算法的运行流程，下面来看如何从bucket总选择子item的问题，主要来看有实际使用价值的straw即straw2算法。</p>
<p>顾名思义，straw算法针对特定输入，为每个元素计算一个签长，从中选择长度最长者作为结果输出。每个签长的计算跟元素自身的权重是有关系的，权重越高，被选中的概率就越高。此时，straw的算法执行结果取决于三个因素：固定输入、元素编号及元素权重，其中元素编号是起随机种子的作用，用以在选择失败后进行重试可以得出不同结果，所以针对特定输入（在ceph里就是pgid），straw的算法只受元素权重的影响。进一步来讲，如果每个元素的签长只和自身权重有关，则可以证明此事straw算法对于集群item变更的处理是最优的，以添加元素为例来说明：</p>
<p>1）假设当前集群中有n个元素：（e1 e2 e3 ….e<sub>n</sub>)</p>
<p>2）向集群中添加新元素e<sub>n+1</sub>，(e1 e2 … e<sub>n</sub>, e<sub>n+1</sub>) </p>
<p>3）假设在n+1加入之前，针对任意输入X，分别计算每个元素的签长为(d1 d2 … d<sub>n</sub>)，并假定其中最大值为d<sub>max</sub>：</p>
<p>4）因为新元素的签长计算只和其自身编号有关，且它的加入不会影响其他元素的签长计算，假设针对输入X，新元素的签长为d<sub>n+1</sub></p>
<p>5）因为straw算法是以最长签长元素作为输入的，如果d<sub>n+1</sub> &gt; d<sub>max</sub>，那么X将被重新映射至新元素e<sub>n+1</sub>，否则则对X的已有映射结果无任何影响</p>
<p>可见，在添加一个元素时，straw会随机得将一些元素映射至新添加的元素中，删除一个元素是，会将该元素中的全部数据随机重新映射，即元素的变更不会导致数据在变更的元素之间迁移（即不会导致额外的数据迁移）。但是原始straw算法在实际使用过程中却被发现会打来额外的数据迁移，社区被迫开始低该算法进行审视，原straw算法伪代码如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">max_x = -1</span><br><span class="line">max_item = -1</span><br><span class="line">for each item:</span><br><span class="line">	x = hash(input, r) * item_straw</span><br><span class="line">	if x &gt; max_x :</span><br><span class="line">		max_x = x</span><br><span class="line">		max_item = item</span><br><span class="line">return max_item</span><br></pre></td></tr></table></figure>
<p>可见，算法的选择结果取决于每个元素输入（input）、随机因子（r）和item_straw（权重），但原有算法中item_straw的计算不但取决于每个元素自身的权重，也和集合中所有其他元素的权重相关，从而导致每个元素变化是会到来额外的数据迁移。新修正后的算法被称之为straw2，其伪代码如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">max_x = -1</span><br><span class="line">max_item = -1</span><br><span class="line">for each item:</span><br><span class="line">	x = hash(input, r) #输出落在[0, 65535]之间</span><br><span class="line">	x = ln(x / 65536) / weight</span><br><span class="line">	if x &gt; max_x :</span><br><span class="line">		max_x = x</span><br><span class="line">		max_item = item</span><br><span class="line">return max_item</span><br></pre></td></tr></table></figure>
<h2 id="CRUSH分析"><a href="#CRUSH分析" class="headerlink" title="CRUSH分析"></a>CRUSH分析</h2><p>理论上来讲，只要选择一个好的哈希函数及合理的权重分配，CRUSH算法是能够保证数据在所有磁盘之间均匀分布的，但是实际使用过程中存在如下问题：</p>
<ul>
<li>集群规模较小时，输入样本不够，不一定能保证数据的均衡</li>
<li>CRUSH算法本身是有缺陷的，前文描述的straw2每次选择item都是计算其独立概率的，但是在实际过程中为了考虑副本的分布策略，却变成了针对item计算条件概率，所以CRUSH也无法真正处理好多副本模式下的副本均匀分布问题</li>
<li>设备的权重一般是根据其容量计算得来的，但是容量更大的硬盘不代表性能更高。所以针对异构集群（特质存在容量不一的OSD设备），CRUSH无法较好处理这种情况</li>
</ul>
<p>因此在实际使用过程中，是允许对CRUSH的计算结果进行人工调整的。在CEPH中，每个设备除了有一个权重之外，还有一个外的reweight，CRUSH在正常选中一个OSD后，还会基于该reweight对OSD进行测试，如果测试失败，则拒绝选择该OSD，reweight调的越高，则测试通过率就越高。weight与reweight的最大区别就是weight是表示osd在crushmap中的权重，它的值一般是固定的，目前一个osd的磁盘主要是根据它的容量来计算的。而reweight是可以在使用过程中调整的，osd的reweight调整不会影响osd之上的bucket的权重，所以对以bucket的选择不会有任何影响，而只是用以选择完osd之后进行一个测试。一般来说，reweight主要是一种临时调整方案，如集群中某些磁盘较满，我们可以在一边扩容的同时，降低这些磁盘的reweight以保持集群的正常使用。</p>
<h2 id="References"><a href="#References" class="headerlink" title="References"></a>References</h2><ul>
<li>Ceph设计原理与实现 [谢型果 等]</li>
<li>Ceph源码分析 [常涛 等]</li>
<li><a href="http://cephnotes.ksperis.com/blog/2014/12/23/difference-between-ceph-osd-reweight-and-ceph-osd-crush-reweight" target="_blank" rel="noopener">Difference Between ‘Ceph Osd Reweight’ and ‘Ceph Osd Crush Reweight’</a></li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://yoursite.com/2018/11/09/linux-memory-manage/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Leeshine">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Leesine's Blog">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2018/11/09/linux-memory-manage/" itemprop="url">Linux 内存管理</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2018-11-09T20:24:04+08:00">
                2018-11-09
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>下面以X86平台下32为机器为例来分析Linux的内存管理机制。</p>
<h2 id="用户进程内存管理"><a href="#用户进程内存管理" class="headerlink" title="用户进程内存管理"></a>用户进程内存管理</h2><p>在多任务操作系统上，每个进行都是运载自己的内存空间里，这就是虚拟内存，在32位机器上，这个虚拟内存空间拥有4GB的寻址能力，通过页表（page table）我们可以将虚拟内存映射成真是的物理地址。Linux默认会将高地址的1GB空间分配给内核使用，剩下的3GB作为用户空间供用户使用，整体的进程地址空间布局如下：</p>
<p><img src="/images/2.png" alt="Linux Memory"></p>
<p>对应的主要区域如下：</p>
<ul>
<li>内核空间：供操作系统内核使用，用户态程序不能访问</li>
</ul>
<ul>
<li>栈：维护函数调用的上下文，向下增长，通常有数M大小。通过系统调用expand_stack()可以将分配栈空间，如果栈空间无法增长了（通常已经到8MB）了，则会发生栈溢出</li>
<li>堆：应用程序动态分区内存区域，通过brk系统调用来向上增长</li>
<li>内存映射区：通过mmap分配，用以映射共享库或映射一个匿名空间供程序使用。mmap是一个高效、方便地操作一个文件，通过mmap将动态库映射至内存中可以实现快速加载，或者通过mmap映射出一个不跟任何文件关联的匿名空间来供用户程进程使用。在Linux中，如果你通过malloc申请一块打内存的话（通常是大于128KB），glibc通常会调用mmap系统调用来分配内存</li>
<li>BSS、DATA、TEXT：存储用户程序数据段、代码段等。其中BSS、DATA存储的都是存储程序全局或静态变量，不同的是BSS存储的是为初始化的变量</li>
</ul>
<p>如上图所示，每个段之间可能会有部分随机偏移值，即每段的开始位置并不是固定的，这样有利于降低被攻击的风险。通过/proc/{pid}/maps这个文件，可以观察进行的内存使用情况。</p>
<h2 id="内核空间内存管理"><a href="#内核空间内存管理" class="headerlink" title="内核空间内存管理"></a>内核空间内存管理</h2><p>如下图所示，Linux中的进程实例是通过<code>task_struct</code>这样一个结构来描述的，该结构中的<code>mm</code>这个域指向一个内存描述符<code>mm_struct</code>，记录了进程执行期间它的内存摘要。如图所示，它存储了进程中每个段的起始位置、物理页的数目、虚拟空间的使用情况等。</p>
<p><img src="/images/7.png" alt=""></p>
<p>在内存描述符中(<code>mm_struct</code>)，我们还可以找到两个重要的结构：虚拟内存区域集合（the set of virtual memory areas ）及页表（page tables）。如下，为一个内存区域集合：</p>
<p><img src="/images/8.png" alt=""></p>
<p>每个VMA（virtual memory area）是一段连续的、不会重叠虚拟地址，一个<code>vm_area_struct</code>实例完整得描述了一个内存区域，包括起始、结束地址，flags描述的访问权限及行为，以及vm_file描述的对应的映射文件（如果有的话，没有的话这段内存区域就是匿名的）。</p>
<p>一个进程的VMA会以两种形式存储在存储在其内存描述符中：以链表的形式存储在mmap域中，以红黑树的心事存储在mm_rb域中。红黑树的形式使得内核可以快速查找出给定虚拟地址对应的内存区域，当我们读取/proc/{pid}/maps文件时，内核可以快速恢复出其VMA链表。</p>
<p>Linux在通常情况下会使用4KB大小的页来映射用户空间的虚拟空间，处理器会通过页表（<code>page tables</code>）来将虚拟地址转换为物理地址，Linux在内存描述符的<code>pgd</code>域中存储了指向进程<code>page tables</code>的指针，每个虚拟内存页在<code>page tables</code>里都会有一个页表项(<code>page table entry(PET)</code>)与之对应，通常来说，PTE在x86架构下是一个大小为4byte的记录，如下所示：</p>
<p><img src="/images/9.png" alt=""></p>
<p>如上各个位的作用如下：</p>
<ul>
<li>P：标识该虚拟页是否在内存中，0表示不在内存中，访问该页会出发缺页异常</li>
<li>R/W：标识是否可读/写，如果为0，则页面为只读</li>
<li>U/S：标识是用户/管理员，如果为0，只能供内核使用</li>
<li>D：标识是否为脏页面，脏页面表示执行过写操作</li>
<li>A：标识是否被访问过</li>
</ul>
<p>虚拟内存并不存储任何东西，仅仅是将一个进程的地址空间映射至真实的物理地址空间上。这个物理地址空间被内核切分成一个个页帧（page frames），它是物理内存管理的最小单位，32为X86架构下，Linux通常采用4KB大小的页帧，每个页帧在内核中都有一个描述符和标志位进行追踪。下面我们把VMA，PTE、page frame连起来看它们是如何工作的，如下所示为一个用户堆内存：</p>
<p><img src="/images/10.png" alt=""></p>
<p>蓝色矩形表示VMA范围内的页，箭头表示通过PTE将虚拟页映射至page frame，没有箭头指出的虚拟页，意味着这个页的P flag为0，即这个虚拟页从来没有被访问或者刚被置换出来。VMA就是进程与内核之间的签约，进程对内核发起请求（内存分配，文件映射等），内核同意后创建或者更新对应的VMA，但它不是立即就将虚拟页映射至物理页，而是在发生缺页异常的时候才会真正映射，所以实际情况是VMA记录进程同内核达成的协议，PTE记录内核实际已经执行了哪些操作。以下为内存分配的一个例子：</p>
<p><img src="/images/11.png" alt=""></p>
<p>当进程通过brk()申请申请内存时，内核只是更新对应VMA后便返回，并没有实际的物理页被分配，当进程访问这个页时，内核会去寻找对应的VMA，如果找到了会做前置检查（读写权限等），如果没找到，说明进程访问了不合理的位置（即之前未与内核达成合同），这就会出发段错误。找到VMA之后，内核会通过查找PTE内从及VMA的类型来解决这个缺页异常（page fault），此时PTE内容为空，之后内核便会分配一个页帧并将PTE指向分配的页帧。</p>
<h2 id="Page-Cache"><a href="#Page-Cache" class="headerlink" title="Page Cache"></a>Page Cache</h2><p>操作系统在操作文件时有两个问题需要解决：</p>
<ul>
<li>相对于内存来说，硬盘的读取速度非常慢</li>
<li>需要做到将文件加载至内存中 一次便可供多个进程共享</li>
</ul>
<p>以上两个问题都可以通过page cache来解决，kernel用它来存储与页面大小相同的文件块。下面用一个render程序为例来描述一个文件的读取过程，render会打开scene.dat文件，每次读取512 byte的内容并将其存入堆内存中，读取流程如下：</p>
<p><img src="/images/3.png" alt=""></p>
<p>读取挖12KB后，render的堆内存及相关页帧如下：</p>
<p><img src="/images/4.png" alt=""></p>
<p>事实上，尽管只调用了read函数，此时也会有三个page cache的页帧中存储了部分scene.dat的部分数据，因为所有的常规文件操作都是通过page cache来进行的，在x86平台上，所有文件在内核看来都是一系列4KB大小的块。即使你只是读取1byte数据，它所在的4KB大小的块都会被复制到page cache中。</p>
<p>不幸的是，为了是用户态程序读取文件内容，内核还需要将page cache中的东西复制到用户内存中，这不但会消耗cpu，同时也会浪费物理内存。如上图所示，scene.dat的内容在内存中存储了两份，而且每个实例都会保存一份。至此，这种读取方式虽然解决磁盘延迟的问题，但会带来较多额外的问题，但使用memory-mapped files却可以解决这些问题，即通过内核将进程的虚拟页面直接映射至page cache中，这样能有效提高文件读写效率，同时也能节省部分物理内存，如下所示：</p>
<p><img src="/images/5.png" alt=""></p>
<p>在使用了page cache的读写时，当进程调用write()时，数据只是被写入到page cache中，对应的页进入dirty状态，磁盘IO不会立刻发生，如果此时主机死机，数据就会丢失，因此重要的数据在写入时必须调用fsync（仍需要注意磁盘驱动缓存）。另一方面，读取操作会阻塞住，直至数据准备好，内核会通过eager loading（积极加载）来加速读取，即预读取部分数据至page cache中。最后，你可以通过<code>O_DIRECT</code>来绕过page cache。</p>
<p>一个文件映射可以是私有的，也可能是共享的，这种区别只有在更改内存中的内容时才能体现出来：私有映射时进程对内存的修改不会提交至磁盘中或者被其他进程所见，而共享映射却可以。内核通过页表项，使用<code>copy on write</code>来实现私有映射。如下示例中，render和render3d同时创建了scene.dat的私有映射，render修改了映射至内存中的文件：</p>
<p><img src="/images/6.png" alt=""></p>
<h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul>
<li><a href="https://manybutfinite.com/post/anatomy-of-a-program-in-memory/" target="_blank" rel="noopener">Anatomy of a Program in Memory</a></li>
<li><a href="https://manybutfinite.com/post/how-the-kernel-manages-your-memory" target="_blank" rel="noopener">How The Kernel Manages Your Memory</a></li>
<li><a href="https://manybutfinite.com/post/page-cache-the-affair-between-memory-and-files/" target="_blank" rel="noopener">Page Cache, the Affair Between Memory and Files</a></li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="page-number current">2</span>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">Leeshine</p>
              <p class="site-description motion-element" itemprop="description">Stay Hungry, Stay Foolish</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">17</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            

            
              
              
              <div class="site-state-item site-state-tags">
                
                  <span class="site-state-item-count">11</span>
                  <span class="site-state-item-name">tags</span>
                
              </div>
            

          </nav>

          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/leeshine" target="_blank" title="Github">
                      
                        <i class="fa fa-fw fa-github"></i>Github</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="mailto:lvshanchun@gmail.com" target="_blank" title="E-Mail">
                      
                        <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; <span itemprop="copyrightYear">2019</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Leeshine</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Muse</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  

  

  

</body>
</html>
